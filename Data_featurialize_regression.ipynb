{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "id_num = pickle.load(open('id_num.txt', 'rb'))\n",
    "train_X = pickle.load(open('train_data.txt', 'rb'))\n",
    "train_y = pickle.load(open('train_y.txt', 'rb'))\n",
    "non_null = pickle.load(open('non_null.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = []\n",
    "for i in range(non_null.shape[1]):\n",
    "    data = train_X[:, i]\n",
    "    real = non_null[:, i]\n",
    "    rd = data[real]\n",
    "    x = str(type(rd[0]))\n",
    "    if 'str' in x:\n",
    "        types.append('str')\n",
    "    elif 'float' in x:\n",
    "        types.append('float')\n",
    "    else:\n",
    "        types.append('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix null in string column first, use the most frequency one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic):\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "# input one array and return the most frequent one\n",
    "def MostFrequentOne(column):\n",
    "    itemfreq = {}\n",
    "    for i in column:\n",
    "        if i not in itemfreq:\n",
    "            itemfreq[i] = 1\n",
    "        else:\n",
    "            itemfreq[i] += 1\n",
    "    tmp_dict = sorted(dict2list(itemfreq), key=lambda d:d[1], reverse=True)\n",
    "    return tmp_dict[0]\n",
    "\n",
    "# return a reverse boolean column\n",
    "def BoolReverse(column):\n",
    "    x = np.zeros(len(column))\n",
    "    x[column] = 1\n",
    "    y = (x==0)\n",
    "    return y\n",
    "\n",
    "#If A column with only one value equals to zero, then it shall be excluded\n",
    "def OneValueIfNeo(column):\n",
    "    x = np.sum(column==0)\n",
    "    if x > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# normalize raw, no mean and std, they shall be computed\n",
    "def Normalize_Raw(column):\n",
    "    mean = np.mean(column)\n",
    "    std = np.std(column)\n",
    "    return mean, std\n",
    "# normalize one column by mean and std\n",
    "def Norm(column, mean, std):\n",
    "    return (column - mean)/std\n",
    "\n",
    "# 0-1 average\n",
    "def NeoOneMean_Raw(column):\n",
    "    maxv = np.max(column)\n",
    "    minv = np.min(column)\n",
    "    return maxv, minv\n",
    "# mean one column to 0-1\n",
    "def NeoOneMean(column, maxv, minv):\n",
    "    return (column - minv) / (maxv - minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the non or null\n",
    "def OneStrColumnFix(column, nn):\n",
    "    mfo = MostFrequentOne(column[nn])\n",
    "    rn = BoolReverse(nn)\n",
    "    column[rn] = mfo\n",
    "    return column\n",
    "\n",
    "# one_hot to map str to int\n",
    "def OneHot_Str(column, retdict = 0):\n",
    "    syms = set(column)\n",
    "    sim = {}\n",
    "    count = 0\n",
    "    for s in syms:\n",
    "        sim[s] = count\n",
    "        count += 1\n",
    "    cl = len(column)\n",
    "    retoh = np.zeros((cl, count))\n",
    "    for i in range(cl):\n",
    "        s = column[i]\n",
    "        mi = sim[s]\n",
    "        retoh[i, mi] = 1.0\n",
    "    if retdict == 0:\n",
    "        return retoh\n",
    "    else:\n",
    "        return retoh, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "231\n",
      "749\n",
      "771\n",
      "942\n",
      "2379\n",
      "3831\n",
      "4106\n",
      "5915\n",
      "6512\n"
     ]
    }
   ],
   "source": [
    "#fix the null in str and one_hot it, concatenate the one_hot columns to the end\n",
    "for i in range(len(types)):\n",
    "    t = types[i]\n",
    "    if t == 'str':\n",
    "        column = train_X[:, i]\n",
    "        nn = non_null[:, i]\n",
    "        column_fixed = OneStrColumnFix(column, nn)\n",
    "        train_X[:, i] = column_fixed\n",
    "        one_hots = OneHot_Str(column_fixed)\n",
    "        train_X = np.concatenate((train_X, one_hots), axis=1)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fix int columns and float columns\n",
    "methods = []\n",
    "#method = 2, normalization 3, meanNeoOne\n",
    "method = 2\n",
    "for i in range(len(types)):\n",
    "    t = types[i]\n",
    "    if t == 'str':\n",
    "        methods.append((i, 0))\n",
    "    else:\n",
    "        data = train_X[:, i]\n",
    "        real = non_null[:, i]\n",
    "        numv = len(set(data[real]))\n",
    "        #fix null\n",
    "        if np.sum(real) < 500:\n",
    "            rn = BoolReverse(real)\n",
    "            if numv == 1:\n",
    "                data[rn] = data[real][0]\n",
    "            else:\n",
    "                data[rn] = np.mean(data[real])\n",
    "        #fix null, then manipulate the column\n",
    "        if numv == 1:\n",
    "            data = np.ones(train_X.shape[0])\n",
    "            methods.append((i, 1))\n",
    "        else:\n",
    "            if method == 2:\n",
    "                mean, std = Normalize_Raw(data)\n",
    "                data = (data-mean)/std\n",
    "                methods.append((i, mean, std))\n",
    "            elif method == 3:\n",
    "                maxv, minv = NeoOneMean_Raw(data)\n",
    "                data = (data - minv)/(maxv - minv)\n",
    "                methods.append((i, maxv, minv))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    return np.mean(np.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7989)\n"
     ]
    }
   ],
   "source": [
    "# now delete all str column\n",
    "stridxs = []\n",
    "for i in range(len(types)):\n",
    "    t = types[i]\n",
    "    if t == 'str':\n",
    "        stridxs.append(i)\n",
    "train_X = np.delete(train_X, stridxs, axis=1)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_m = np.mean(train_y)\n",
    "y_s = np.std(train_y)\n",
    "train_y = (train_y-y_m)/y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.999999968443\n",
      "1 0.999999983275\n",
      "2 0.999999992392\n",
      "3 0.999999999294\n",
      "4 0.999999999902\n",
      "5 0.99999999996\n",
      "6 0.999999999979\n",
      "7 0.999999999994\n",
      "8 0.999999999997\n",
      "9 0.999999999998\n",
      "10 0.999999999999\n",
      "11 0.999999999999\n",
      "12 0.999999999999\n",
      "13 1.0\n",
      "14 1.0\n",
      "new shape (500, 15)\n"
     ]
    }
   ],
   "source": [
    "cn = 15 \n",
    "pca = PCA(n_components=cn) \n",
    "pca.fit(train_X) \n",
    "psum = 0 \n",
    "pe = pca.explained_variance_ratio_\n",
    "for i in range(cn): \n",
    "    e = pe[i] \n",
    "    psum += e \n",
    "    print(i, psum) \n",
    "X_new = pca.transform(train_X) \n",
    "print(\"new shape\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cn):\n",
    "    data = X_new[:, i]\n",
    "    mean, std = Normalize_Raw(data)\n",
    "    data = (data - mean) / std\n",
    "    X_new[:, i] = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.06191318  0.30225538 -0.32706471 ..., -1.63407943 -0.46975306\n",
      "   0.38670017]\n",
      " [-0.94169659 -0.15128664 -1.00714045 ..., -0.52040649  0.6231931\n",
      "   1.90539893]\n",
      " [-0.9416966  -0.37398339 -0.82482787 ..., -0.51219074  0.04798749\n",
      "   0.62511736]\n",
      " ..., \n",
      " [-0.9416966  -1.16272784  0.73796304 ...,  1.01348782 -0.94394529\n",
      "  -1.9971444 ]\n",
      " [ 1.06191317 -1.03518188  1.78971803 ...,  1.39034844  0.23757798\n",
      "  -0.19830898]\n",
      " [-0.9416966  -0.30308045 -1.04353053 ...,  0.59632295 -1.28882662\n",
      "  -2.79696366]]\n"
     ]
    }
   ],
   "source": [
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now model and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(int(time.time()))\n",
    "idxs = np.arange(len(train_X))\n",
    "np.random.shuffle(idxs)\n",
    "train_X = train_X[idxs]\n",
    "train_y = train_y[idxs]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15) \n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "for i in range(cn):\n",
    "    mean, std = np.mean(X_train[:, i]), np.std(X_train[:, i])\n",
    "    X_train[:, i] = (X_train[:, i] - mean) / std\n",
    "    X_test[:, i] = (X_test[:, i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_len = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(input_data):\n",
    "    l1 = tf.layers.dense(input_data, 1000)\n",
    "    l2 = tf.layers.dense(l1, 100)\n",
    "    l3 = tf.layers.dense(l2, 10)\n",
    "    l4 = tf.layers.dense(l3, 1)\n",
    "    return l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_f(y, y_pred):\n",
    "    y = y*y_s+y_m\n",
    "    y_pred = y_pred*y_s+y_m\n",
    "    return tf.reduce_mean(tf.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = tf.placeholder(shape=[None, column_len], dtype=tf.float32)\n",
    "input_y = tf.placeholder(shape=[None], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model(input_X)\n",
    "loss = loss_f(pred_y, input_y) \n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0461244\n",
      "1 0.0427383\n",
      "2 0.045103\n",
      "3 0.0420402\n",
      "4 0.0403142\n",
      "5 0.0413477\n",
      "6 0.0423951\n",
      "7 0.0419504\n",
      "8 0.0408584\n",
      "9 0.040265\n",
      "10 0.0404792\n",
      "11 0.0409928\n",
      "12 0.0412035\n",
      "13 0.0409727\n",
      "14 0.0405532\n",
      "15 0.040262\n",
      "16 0.0402563\n",
      "17 0.0404607\n",
      "18 0.0406522\n",
      "19 0.0406595\n",
      "20 0.040498\n",
      "21 0.040311\n",
      "22 0.0402206\n",
      "23 0.0402491\n",
      "24 0.0403385\n",
      "25 0.0404097\n",
      "26 0.0404115\n",
      "27 0.0403459\n",
      "28 0.0402606\n",
      "29 0.0402115\n",
      "30 0.0402209\n",
      "31 0.0402667\n",
      "32 0.0403042\n",
      "33 0.0403049\n",
      "34 0.0402729\n",
      "35 0.0402332\n",
      "36 0.0402103\n",
      "37 0.0402131\n",
      "38 0.0402332\n",
      "39 0.0402526\n",
      "40 0.0402548\n",
      "41 0.0402387\n",
      "42 0.0402177\n",
      "43 0.0402068\n",
      "44 0.0402101\n",
      "45 0.040221\n",
      "46 0.0402292\n",
      "47 0.0402287\n",
      "48 0.0402201\n",
      "49 0.0402103\n",
      "50 0.040206\n",
      "51 0.0402086\n",
      "52 0.0402144\n",
      "53 0.040218\n",
      "54 0.0402163\n",
      "55 0.0402112\n",
      "56 0.0402067\n",
      "57 0.0402061\n",
      "58 0.0402084\n",
      "59 0.0402112\n",
      "60 0.0402117\n",
      "61 0.04021\n",
      "62 0.0402072\n",
      "63 0.0402055\n",
      "64 0.0402063\n",
      "65 0.0402078\n",
      "66 0.0402088\n",
      "67 0.0402082\n",
      "68 0.0402067\n",
      "69 0.0402058\n",
      "70 0.0402058\n",
      "71 0.0402065\n",
      "72 0.0402071\n",
      "73 0.040207\n",
      "74 0.0402064\n",
      "75 0.0402059\n",
      "76 0.0402057\n",
      "77 0.0402061\n",
      "78 0.0402063\n",
      "79 0.0402063\n",
      "80 0.040206\n",
      "81 0.0402057\n",
      "82 0.0402055\n",
      "83 0.0402057\n",
      "84 0.0402061\n",
      "85 0.0402061\n",
      "86 0.0402057\n",
      "87 0.0402058\n",
      "88 0.0402055\n",
      "89 0.0402058\n",
      "90 0.0402059\n",
      "91 0.0402059\n",
      "92 0.0402057\n",
      "93 0.0402057\n",
      "94 0.0402055\n",
      "95 0.0402056\n",
      "96 0.0402057\n",
      "97 0.0402057\n",
      "98 0.0402056\n",
      "99 0.0402056\n",
      "100 0.0402056\n"
     ]
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    _, l = sess.run([opt, loss], feed_dict={input_X:X_train, input_y:y_train})\n",
    "    #l = sess.run(loss, feed_dict={input_X:X_test, input_y:y_test})\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('测试A.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testlb = pd.read_csv('测试A-答案模板.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "firstdelete = pickle.load(open('firstdelete.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnn = test_data.isnull().values\n",
    "test_data = test_data.values\n",
    "test_data = np.delete(test_data, firstdelete, axis=1)\n",
    "testnn = np.delete(testnn, firstdelete, axis=1)\n",
    "test_nn = testnn[:, 1:]\n",
    "test_id = test_data[:, 0]\n",
    "test_X = test_data[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpn = np.zeros(test_nn.shape)\n",
    "tmpn[test_nn] = 1\n",
    "test_nn = tmpn==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttypes = []\n",
    "for i in range(test_X.shape[1]):\n",
    "    nn = test_nn[:, i]\n",
    "    data = test_X[:, i]\n",
    "    rd = data[nn]\n",
    "    strtype = str(type(rd[0]))\n",
    "    if 'str' in strtype:\n",
    "        ttypes.append('str')\n",
    "    elif 'float' in strtype:\n",
    "        ttypes.append('float')\n",
    "    else:\n",
    "        ttypes.append('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array(types)\n",
    "t2 = np.array(ttypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7674 7965\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(t1==t2), len(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
