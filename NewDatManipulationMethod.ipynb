{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read train and test data\n",
    "train_data = pd.read_excel('训练.xlsx')\n",
    "test_data_1 = pd.read_excel('测试A.xlsx')\n",
    "test_data_2 = pd.read_excel('测试B.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nonnull = train_data.isnull().values\n",
    "test_nonnull_1 = test_data_1.isnull().values\n",
    "test_nonnull_2 = test_data_2.isnull().values\n",
    "train_X = train_data.values\n",
    "test_X_1 = test_data_1.values\n",
    "test_X_2 = test_data_2.values\n",
    "test_id_1 = test_X_1[:, 0]\n",
    "test_id_2 = test_X_2[:, 0]\n",
    "train_y = train_X[:, -1]\n",
    "train_X = train_X[:, 1:-1]\n",
    "test_X_1 = test_X_1[:, 1:]\n",
    "test_X_2 = test_X_2[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 8027), (100, 8027), (121, 8027))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X_1.shape, test_X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027) (721, 8027)\n"
     ]
    }
   ],
   "source": [
    "#Merge two data\n",
    "merged_X = np.concatenate((train_X, test_X_1, test_X_2), axis=0)\n",
    "merged_nn = np.concatenate((train_nonnull[:, 1:-1], test_nonnull_1[:, 1:], test_nonnull_2[:, 1:]), axis=0)\n",
    "print(merged_X.shape, merged_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reverse nn\n",
    "def BoolReverse(columns):\n",
    "    tmpm = np.zeros(columns.shape)\n",
    "    tmpm[columns] = 1\n",
    "    return tmpm == 0\n",
    "\n",
    "merged_nn = BoolReverse(merged_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# now find the values that has 0 value and delete such column\n",
    "first_delete_idxs = []\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    if len(rd) == 0:\n",
    "        first_delete_idxs.append(i)\n",
    "    elif len(set(rd)) == 0:\n",
    "        first_delete_idxs.append(i)\n",
    "print(len(first_delete_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027)\n",
      "(721, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(merged_X.shape)\n",
    "merged_X = np.delete(merged_X, first_delete_idxs, axis=1)\n",
    "print(merged_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027)\n",
      "(721, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(merged_nn.shape)\n",
    "merged_nn = np.delete(merged_nn, first_delete_idxs, axis=1)\n",
    "print(merged_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n"
     ]
    }
   ],
   "source": [
    "#now find the columns that has only one value\n",
    "only_one_values = 0\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    if len(set(rd)) == 1:\n",
    "        merged_X[:, i] = 1.0\n",
    "        merged_nn[:, i] = True\n",
    "        only_one_values += 1\n",
    "print(only_one_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic):\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "# input one array and return the most frequent one\n",
    "def MostFrequentOne(column):\n",
    "    itemfreq = {}\n",
    "    for i in column:\n",
    "        if i not in itemfreq:\n",
    "            itemfreq[i] = 1\n",
    "        else:\n",
    "            itemfreq[i] += 1\n",
    "    tmp_dict = sorted(dict2list(itemfreq), key=lambda d:d[1], reverse=True)\n",
    "    return tmp_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one_hot to map str to int\n",
    "def OneHot_Str(column, retdict = 0):\n",
    "    syms = set(column)\n",
    "    sim = {}\n",
    "    count = 0\n",
    "    for s in syms:\n",
    "        sim[s] = count\n",
    "        count += 1\n",
    "    cl = len(column)\n",
    "    retoh = np.zeros((cl, count))\n",
    "    for i in range(cl):\n",
    "        s = column[i]\n",
    "        mi = sim[s]\n",
    "        retoh[i, mi] = 1.0\n",
    "    if retdict == 0:\n",
    "        return retoh\n",
    "    else:\n",
    "        return retoh, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(721, 7999)\n",
      "(721, 7989)\n"
     ]
    }
   ],
   "source": [
    "#now fix the remain data\n",
    "#if the values in data has one value that is string, then one_hot it, else normalize it\n",
    "stridxs = []\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    #if len(data) == len(rd) and np.mean(data) == 1.0:\n",
    "    #    continue\n",
    "    isstr = False\n",
    "    for j in range(len(rd)):\n",
    "        x = rd[j]\n",
    "        sx = str(type(x))\n",
    "        if 'str' in sx:\n",
    "            isstr = True\n",
    "            break\n",
    "    if isstr:\n",
    "        stridxs.append(i)\n",
    "        # fix null and one_hot it\n",
    "        if len(rd) < len(data):\n",
    "            mfc = MostFrequentOne(rd)\n",
    "            rn = BoolReverse(real)\n",
    "            data[rn] = mfc\n",
    "        onehots = OneHot_Str(data)\n",
    "        merged_X = np.concatenate((merged_X, onehots), axis=1)\n",
    "    else:\n",
    "        if len(rd) < len(data):\n",
    "            if len(set(data)) == 1:\n",
    "                continue\n",
    "            rn = BoolReverse(real)\n",
    "            data[rn] = np.mean(rd)\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "            data = (data-mean)/std\n",
    "            merged_X[:, i] = data\n",
    "#delete the string columns\n",
    "print(len(stridxs))\n",
    "print(merged_X.shape)\n",
    "merged_X = np.delete(merged_X, stridxs, axis=1)\n",
    "print(merged_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3beeaf33c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.20190859305\n"
     ]
    }
   ],
   "source": [
    "tyl = np.sort(train_y)\n",
    "mean_y = np.mean(tyl)\n",
    "std_y = np.std(tyl)\n",
    "tyl = (tyl-np.mean(tyl))/np.std(tyl)\n",
    "newn = []\n",
    "for i in tyl:\n",
    "    x = float(i)\n",
    "    newn.append(np.arctan(x))\n",
    "tyl = np.array(newn)\n",
    "#tyl = np.sqrt(tyl)\n",
    "plt.plot(np.arange(len(train_y)), tyl)\n",
    "plt.show()\n",
    "print(np.min(tyl))\n",
    "bias_y = np.min(tyl)\n",
    "tyl -= bias_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, vaX, tr_y, va_y = train_test_split(merged_X[:500], train_y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'eta': 0.1,\n",
    "    'max_depth':5,   \n",
    "    'min_child_weight':3,\n",
    "    'gamma':0.1, \n",
    "    'lambda':3,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'reg:gamma',\n",
    "    'nthread':4,\n",
    "    #'scale_pos_weight': 1,\n",
    "    'seed':1000,\n",
    "    'silent':1 ,\n",
    "    #'eval_metric': 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(trX, tr_y)\n",
    "num_rounds = 400\n",
    "plst = params.items()\n",
    "model = xgb.train(plst, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_ans(y):\n",
    "    y += bias_y\n",
    "    y *= std_y\n",
    "    y += mean_y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(vaX)\n",
    "ans = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03846938784034684\n"
     ]
    }
   ],
   "source": [
    "print(MSE_np(ans, va_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEWCAYAAABSaiGHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERHpCjU4IiLSFWpwRESkK/4/1s4YOLexBm4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c24239dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029035031935667206\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(merged_X[:500], train_y)\n",
    "num_rounds = 400\n",
    "plst = params.items()\n",
    "model = xgb.train(plst, dtrain, num_rounds)\n",
    "ta = model.predict(dtrain)\n",
    "print(MSE_np(ta, train_y))\n",
    "dtest = xgb.DMatrix(merged_X[500:600])\n",
    "test1_pred = model.predict(dtest)\n",
    "test1_pred = test1_pred.reshape(100)\n",
    "save = pd.DataFrame({'ID':test_id_1, 'value':test1_pred})\n",
    "save.to_csv('answer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    n_estimators=30,#三十棵树\n",
    "    learning_rate =0.3,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'reg:gamma',\n",
    "    nthread=12,\n",
    "    scale_pos_weight=1,\n",
    "    reg_lambda=1,\n",
    "    seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(trX, label=tr_y)\n",
    "d_valid = xgb.DMatrix(vaX, label=va_y)\n",
    "d_test = xgb.DMatrix(merged_X[500:600])\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-gamma-nloglik:4.63447\tvalid-gamma-nloglik:4.6224\n",
      "Multiple eval metrics have been passed: 'valid-gamma-nloglik' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gamma-nloglik hasn't improved in 500 rounds.\n",
      "[10]\ttrain-gamma-nloglik:2.65673\tvalid-gamma-nloglik:2.65088\n",
      "[20]\ttrain-gamma-nloglik:2.16034\tvalid-gamma-nloglik:2.15676\n"
     ]
    }
   ],
   "source": [
    "model_bst = xgb.train(params, d_train, 30, watchlist, early_stopping_rounds=500, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 30)\n",
      "(100, 30)\n"
     ]
    }
   ],
   "source": [
    "trnew = model_bst.predict(d_train, pred_leaf=True)\n",
    "print(trnew.shape)\n",
    "vanew = model_bst.predict(d_valid, pred_leaf=True)\n",
    "print(vanew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(trnew, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04724269015666128"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_np(va_y, lr.predict(vanew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = merged_X[:500]\n",
    "trX, vaX, tr_y, va_y = train_test_split(trainX, train_y, test_size=0.5, random_state=25)\n",
    "tmp_r = Regressor(2)\n",
    "tmp_r.fit(trX, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00653264688653365\n",
      "0.0356420475014934\n"
     ]
    }
   ],
   "source": [
    "pred_y = tmp_r.predict(trX)\n",
    "print(MSE_np(pred_y, tr_y))\n",
    "pred_y = tmp_r.predict(vaX)\n",
    "print(MSE_np(pred_y, va_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_pred = tmp_r.predict(merged_X[500:600])\n",
    "test1_pred = test1_pred.reshape(100)\n",
    "save = pd.DataFrame({'ID':test_id_1, 'value':test1_pred})\n",
    "save.to_csv('answer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now use pca to reduce its demension\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.999999975997 0.999999975997\n",
      "1 0.999999988161 1.21642303191e-08\n",
      "2 0.999999996208 8.04744349027e-09\n",
      "3 0.999999999192 2.98389444005e-09\n",
      "4 0.999999999921 7.29025967026e-10\n",
      "5 0.999999999973 5.15364429733e-11\n",
      "6 0.999999999996 2.29004577611e-11\n",
      "7 0.999999999998 2.21812415711e-12\n",
      "8 0.999999999999 1.16480649017e-12\n",
      "9 0.999999999999 4.05106542261e-13\n",
      "10 1.0 3.5635447094e-13\n",
      "11 1.0 6.3991617151e-14\n",
      "12 1.0 4.38334783537e-14\n",
      "13 1.0 2.07982605367e-14\n",
      "14 1.0 1.57174133905e-14\n",
      "15 1.0 2.20683238919e-15\n",
      "16 1.0 1.60405629901e-15\n",
      "17 1.0 1.79635425041e-17\n",
      "18 1.0 8.41521642388e-18\n",
      "19 1.0 5.46518582808e-18\n",
      "20 1.0 2.57848357376e-18\n",
      "21 1.0 1.57896209797e-18\n",
      "22 1.0 1.06665620695e-18\n",
      "23 1.0 8.67680041323e-19\n",
      "24 1.0 8.1114062698e-19\n",
      "new shape (721, 25)\n"
     ]
    }
   ],
   "source": [
    "cn = 25\n",
    "pca = PCA(n_components=cn)\n",
    "#pca = KernelPCA(n_components=cn, kernel='rbf') \n",
    "pca.fit(merged_X) \n",
    "psum = 0 \n",
    "pe = pca.explained_variance_ratio_\n",
    "#pe = pca.lambdas_\n",
    "for i in range(cn): \n",
    "    e = pe[i] \n",
    "    psum += e \n",
    "    print(i, psum, e) \n",
    "X_new = pca.transform(merged_X) \n",
    "print(\"new shape\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize new_X\n",
    "for i in range(cn):\n",
    "    col = X_new[:, i]\n",
    "    m = np.mean(col)\n",
    "    s = np.std(col)\n",
    "    #print(i, np.max(col), np.min(col), m, s)\n",
    "    col = (col-m)/s\n",
    "    #print(i, np.max(col), np.min(col), np.mean(col), np.std(col))\n",
    "    mean = np.mean(col)\n",
    "    std = np.std(col)\n",
    "    col = (col-mean)/std\n",
    "    #print(i, np.mean(col), np.std(col))\n",
    "    X_new[:, i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 25) (100, 25) (121, 25)\n"
     ]
    }
   ],
   "source": [
    "# split train, test1, test2 data\n",
    "trainX = X_new[:500]\n",
    "test1X = X_new[500:600]\n",
    "test2X = X_new[600:]\n",
    "print(trainX.shape, test1X.shape, test2X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regression by machinr learn\n",
    "def MSE_np(y, y_pred):\n",
    "    return np.mean(np.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, vaX, tr_y, va_y = train_test_split(trainX, train_y, test_size=0.5, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = Regressor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(trX, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006243235640536375\n"
     ]
    }
   ],
   "source": [
    "tr_p = regressor.predict(trX)\n",
    "print(MSE_np(tr_y, tr_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038457481925419826\n"
     ]
    }
   ],
   "source": [
    "va_p = regressor.predict(vaX)\n",
    "print(MSE_np(va_y, va_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0059782197103562746\n"
     ]
    }
   ],
   "source": [
    "regressor = Regressor(2)\n",
    "regressor.fit(trainX, train_y)\n",
    "trainp = regressor.predict(trainX)\n",
    "print(MSE_np(train_y, trainp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_pred = regressor.predict(test1X)\n",
    "test1_pred = test1_pred.reshape(100)\n",
    "save = pd.DataFrame({'ID':test_id_1, 'value':test1_pred})\n",
    "save.to_csv('answer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# it is a bit fusion to combat all codes from pca to predict to get an good result to get the best prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 : GradientBoostingRegressor\n",
    "# 1 : ExtraTreesRegressor\n",
    "# 2 : RandomForestRegressor\n",
    "# 3 : SVM Regressor(RBF Kernel)\n",
    "# 4 : KNN Regressor(Distance-weighted)\n",
    "# 5 : Decision TreeRegressor\n",
    "# 6 : KNN Regressor (Uniform-weighted)\n",
    "# 7 : LinearRegression\n",
    "# 8 : SGDRegressor\n",
    "# 9 : SVM Regressor(Linear Kernel)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "def Regressor(number):\n",
    "    if number == 0:\n",
    "        return GradientBoostingRegressor()\n",
    "    elif number == 1:\n",
    "        return ExtraTreesRegressor()\n",
    "    elif number == 2:\n",
    "        return RandomForestRegressor()\n",
    "    elif number == 3:\n",
    "        return SVR(kernel='rbf')\n",
    "    elif number == 4:\n",
    "        return KNeighborsRegressor(weights='distance')\n",
    "    elif number == 5:\n",
    "        return DecisionTreeRegressor()\n",
    "    elif number == 6:\n",
    "        return KNeighborsRegressor(weights='uniform')\n",
    "    elif number == 7:\n",
    "        return LinearRegression()\n",
    "    elif number == 8:\n",
    "        return SGDRegressor()\n",
    "    elif number == 9:\n",
    "        return SVR(kernel='linear')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12 4.421818017959595 0.0361337366481\n",
      "0 13 5.161895990371704 0.0364379225721\n",
      "0 14 4.634726524353027 0.0366321965281\n",
      "0 15 5.518438339233398 0.0368889988946\n",
      "0 16 5.839105844497681 0.0369648912494\n",
      "0 17 5.7945966720581055 0.0367746618891\n",
      "0 18 6.011782884597778 0.0366208597722\n",
      "0 19 6.2275230884552 0.0367523276268\n",
      "0 20 6.504511833190918 0.0371308668496\n",
      "0 21 6.707685232162476 0.037134715178\n",
      "0 22 6.737461566925049 0.0368297710411\n",
      "0 23 6.906983852386475 0.0364255420531\n",
      "0 24 6.313341379165649 0.0364456896303\n",
      "0 25 6.551576375961304 0.0360109032812\n",
      "0 26 7.459532976150513 0.0360653527262\n",
      "0 27 7.669758081436157 0.0363514185931\n",
      "0 28 7.875925540924072 0.0364369459674\n",
      "0 29 7.975120544433594 0.0364017276903\n",
      "0 30 8.202184200286865 0.0365215516008\n",
      "0 31 8.378604412078857 0.0363816925565\n",
      "0 32 8.559360265731812 0.0362917413953\n",
      "0 33 7.9645607471466064 0.0363089103697\n",
      "0 34 8.14734435081482 0.0364723748086\n",
      "0 35 9.1381995677948 0.0364645462011\n",
      "0 36 9.283891916275024 0.0363806805558\n",
      "0 37 9.53617000579834 0.036257141197\n",
      "0 38 9.655152320861816 0.036373157297\n",
      "0 39 9.861554384231567 0.0364366853007\n",
      "0 40 10.054752588272095 0.0364174258225\n",
      "0 41 9.439269542694092 0.036575275536\n",
      "0 42 9.598021745681763 0.0366352112245\n",
      "0 43 10.670432329177856 0.0368023663005\n",
      "0 44 10.774628639221191 0.0366996920843\n",
      "0 45 10.994583129882812 0.0367653000051\n",
      "0 46 11.115633726119995 0.0369667114292\n",
      "0 47 11.244222640991211 0.037019626359\n",
      "0 48 11.497002840042114 0.0367127215838\n",
      "0 49 10.857229471206665 0.0364306147877\n",
      "1 12 3.033024311065674 0.0431921678705\n",
      "1 13 3.095142364501953 0.0433302731156\n",
      "1 14 3.1082777976989746 0.0433412083771\n",
      "1 15 3.152402639389038 0.0436001912308\n",
      "1 16 3.1879215240478516 0.043447785314\n",
      "1 17 3.2379679679870605 0.0434454451167\n",
      "1 18 3.282728433609009 0.0431918698657\n",
      "1 19 3.3221518993377686 0.0425531081914\n",
      "1 20 3.386606216430664 0.0422895004354\n",
      "1 21 3.4231293201446533 0.0417441098032\n",
      "1 22 3.451493978500366 0.0411089801392\n",
      "1 23 3.4898602962493896 0.041171400308\n",
      "1 24 3.537036895751953 0.0403982206153\n",
      "1 25 3.6088979244232178 0.0398102130533\n",
      "1 26 3.631723165512085 0.0398875948123\n",
      "1 27 2.8886616230010986 0.0398034898288\n",
      "1 28 3.732207775115967 0.0397560480201\n",
      "1 29 3.7075631618499756 0.0394672263838\n",
      "1 30 3.05108904838562 0.039588100623\n",
      "1 31 3.834345817565918 0.0389120664017\n",
      "1 32 3.879685401916504 0.0388522692939\n",
      "1 33 3.9189705848693848 0.0388507861621\n",
      "1 34 3.8986215591430664 0.038738564337\n",
      "1 35 3.9668798446655273 0.0385809255552\n",
      "1 36 4.03863263130188 0.0389073937018\n",
      "1 37 4.079497337341309 0.0384735788699\n",
      "1 38 4.131577253341675 0.0384659588819\n",
      "1 39 4.148276090621948 0.038622125377\n",
      "1 40 4.194551944732666 0.0387003855561\n",
      "1 41 4.238061904907227 0.0387882928865\n",
      "1 42 4.241615533828735 0.0383091135196\n",
      "1 43 4.29706597328186 0.0384862246845\n",
      "1 44 4.348925590515137 0.0386825745625\n",
      "1 45 3.613192319869995 0.0386403009846\n",
      "1 46 4.44410514831543 0.0385799999418\n",
      "1 47 3.7259011268615723 0.0387545802177\n",
      "1 48 4.491000413894653 0.0387130901313\n",
      "1 49 4.586059093475342 0.0381445585186\n",
      "2 12 3.7070353031158447 0.0379591390244\n",
      "2 13 3.803358316421509 0.0379798084369\n",
      "2 14 3.8598406314849854 0.0382250274867\n",
      "2 15 3.984957695007324 0.0388418651897\n",
      "2 16 4.104686975479126 0.0384674746505\n",
      "2 17 4.220142364501953 0.0385878184655\n",
      "2 18 4.2979466915130615 0.0383407691898\n",
      "2 19 4.385266304016113 0.0382926309013\n",
      "2 20 4.475281238555908 0.0380855036185\n",
      "2 21 4.51188850402832 0.0377626415055\n",
      "2 22 4.635089874267578 0.0372883528742\n",
      "2 23 4.258334398269653 0.0373247471149\n",
      "2 24 4.724879026412964 0.036697594663\n",
      "2 25 4.807650566101074 0.0366934675479\n",
      "2 26 4.167182683944702 0.0363464603355\n",
      "2 27 5.085635423660278 0.036712127752\n",
      "2 28 5.174046993255615 0.0365432410439\n",
      "2 29 5.281256914138794 0.0366778190399\n",
      "2 30 5.352508306503296 0.0360907980722\n",
      "2 31 5.430352210998535 0.0364591468396\n",
      "2 32 5.534074544906616 0.0363303904928\n",
      "2 33 5.647978067398071 0.0365649980715\n",
      "2 34 5.722433805465698 0.0362481239972\n",
      "2 35 5.844846963882446 0.0365227765024\n",
      "2 36 5.888343334197998 0.0362216486217\n",
      "2 37 5.155288457870483 0.036076127523\n",
      "2 38 6.049381494522095 0.0365245226454\n",
      "2 39 5.377722501754761 0.0362321468283\n",
      "2 40 6.1925742626190186 0.0365497307973\n",
      "2 41 6.393813610076904 0.0364795737339\n",
      "2 42 6.496490716934204 0.036756902148\n",
      "2 43 6.632193088531494 0.0369222218016\n",
      "2 44 6.683760166168213 0.0366179643386\n",
      "2 45 6.784948825836182 0.0367261400604\n",
      "2 46 6.8500025272369385 0.0368376922316\n",
      "2 47 6.184098243713379 0.0367836122673\n",
      "2 48 6.176808595657349 0.0368544538553\n",
      "2 49 6.365014314651489 0.0365329414309\n",
      "3 12 1.5329091548919678 0.0365012545066\n",
      "3 13 1.6615376472473145 0.0367204594368\n",
      "3 14 1.663287878036499 0.0369452215359\n",
      "3 15 1.6807920932769775 0.0370433708477\n",
      "3 16 1.6769185066223145 0.037111429759\n",
      "3 17 1.699580430984497 0.0371677424722\n",
      "3 18 1.696197748184204 0.0371605125226\n",
      "3 19 1.7238492965698242 0.0373172864311\n",
      "3 20 1.7339608669281006 0.0372815394001\n",
      "3 21 1.7447915077209473 0.0374110572344\n",
      "3 22 1.7521438598632812 0.0375001913782\n",
      "3 23 1.7449438571929932 0.0375640777832\n",
      "3 24 1.7695775032043457 0.0376735651633\n",
      "3 25 1.7720654010772705 0.0376859957149\n",
      "3 26 1.7760603427886963 0.0372989821234\n",
      "3 27 1.7884597778320312 0.0371017832961\n",
      "3 28 1.796274185180664 0.0371431103278\n",
      "3 29 1.8099024295806885 0.0370550426213\n",
      "3 30 1.8361365795135498 0.037092675368\n",
      "3 31 1.8169233798980713 0.0368569560122\n",
      "3 32 1.8196439743041992 0.0367712941246\n",
      "3 33 1.8387749195098877 0.0367921807324\n",
      "3 34 1.8514113426208496 0.036792260092\n",
      "3 35 1.8508656024932861 0.0368190936931\n",
      "3 36 1.862382411956787 0.0368583826708\n",
      "3 37 1.8754220008850098 0.0368737070317\n",
      "3 38 1.8805384635925293 0.0367805084879\n",
      "3 39 1.8851432800292969 0.036766293895\n",
      "3 40 1.8893818855285645 0.0367417792097\n",
      "3 41 1.8987550735473633 0.0368431247165\n",
      "3 42 1.9127655029296875 0.0368664736458\n",
      "3 43 1.936493158340454 0.0368912518364\n",
      "3 44 1.7926390171051025 0.0369129043287\n",
      "3 45 1.9524447917938232 0.0366441269637\n",
      "3 46 1.9602422714233398 0.0365281726787\n",
      "3 47 1.9672365188598633 0.0366315681679\n",
      "3 48 1.9733517169952393 0.0366597157071\n",
      "3 49 1.8088741302490234 0.0365999763847\n",
      "4 12 1.1131699085235596 0.0396139530602\n",
      "4 13 1.1132266521453857 0.0396245225197\n",
      "4 14 1.106342077255249 0.0398054084893\n",
      "4 15 1.1362802982330322 0.0398451448646\n",
      "4 16 1.1420190334320068 0.0398492525612\n",
      "4 17 1.1375489234924316 0.0398495866797\n",
      "4 18 1.1502423286437988 0.0397535679825\n",
      "4 19 1.1677074432373047 0.0399029260224\n",
      "4 20 1.1708970069885254 0.0402267318924\n",
      "4 21 1.188985824584961 0.0396822095127\n",
      "4 22 1.1929969787597656 0.0395254680614\n",
      "4 23 1.196056842803955 0.0394500549643\n",
      "4 24 1.2112770080566406 0.0383470453252\n",
      "4 25 1.2119646072387695 0.0383352637937\n",
      "4 26 1.2086739540100098 0.0383676854373\n",
      "4 27 1.235276699066162 0.0383203209729\n",
      "4 28 1.224121332168579 0.0383182302802\n",
      "4 29 1.2522106170654297 0.0384085623354\n",
      "4 30 1.247469186782837 0.0384060465244\n",
      "4 31 1.2407231330871582 0.0380993861976\n",
      "4 32 1.2791357040405273 0.0381000779254\n",
      "4 33 1.2727100849151611 0.0380845599367\n",
      "4 34 1.2821018695831299 0.0380785860372\n",
      "4 35 1.2831518650054932 0.0380751422809\n",
      "4 36 1.306103229522705 0.0380694004484\n",
      "4 37 1.306861162185669 0.0380578271867\n",
      "4 38 1.303056001663208 0.0379662823948\n",
      "4 39 1.3253870010375977 0.037980118584\n",
      "4 40 1.3089501857757568 0.0377261030338\n",
      "4 41 1.3460655212402344 0.0380887168731\n",
      "4 42 1.354339361190796 0.0380755560966\n",
      "4 43 1.3917298316955566 0.0380933553984\n",
      "4 44 1.3882436752319336 0.0381153881996\n",
      "4 45 1.3927762508392334 0.0378342394704\n",
      "4 46 1.3694944381713867 0.0381426004169\n",
      "4 47 1.416994333267212 0.0377303908238\n",
      "4 48 1.4172818660736084 0.0375106255852\n",
      "4 49 1.4177286624908447 0.0373326556506\n",
      "5 12 1.2113704681396484 0.0559387580002\n",
      "5 13 1.2435297966003418 0.0559950172241\n",
      "5 14 1.238119125366211 0.0566652076693\n",
      "5 15 1.2539474964141846 0.0567856207608\n",
      "5 16 1.2878236770629883 0.0577818649451\n",
      "5 17 1.3146498203277588 0.0575750940969\n",
      "5 18 1.3228180408477783 0.0578672253\n",
      "5 19 1.3432567119598389 0.0576138360369\n",
      "5 20 1.1562492847442627 0.0590131864985\n",
      "5 21 1.3867290019989014 0.0593470385644\n",
      "5 22 1.4262018203735352 0.0585498247217\n",
      "5 23 1.4022133350372314 0.0588969639131\n",
      "5 24 1.4108712673187256 0.0590822053658\n",
      "5 25 1.4554965496063232 0.0592218176205\n",
      "5 26 1.4582293033599854 0.058967848994\n",
      "5 27 1.483407974243164 0.0593231502236\n",
      "5 28 1.4976961612701416 0.0592294419049\n",
      "5 29 1.5205247402191162 0.0595278092883\n",
      "5 30 1.5549697875976562 0.0592418300749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 31 1.572618007659912 0.0588375043001\n",
      "5 32 1.5785109996795654 0.059568040754\n",
      "5 33 1.6011929512023926 0.0593986341236\n",
      "5 34 1.601088047027588 0.0599407438294\n",
      "5 35 2.4089908599853516 0.0595347554012\n",
      "5 36 2.4055018424987793 0.0601335901016\n",
      "5 37 2.392737865447998 0.0603387625446\n",
      "5 38 2.4781479835510254 0.0601733268981\n",
      "5 39 2.4932706356048584 0.0602468249606\n",
      "5 40 2.516441583633423 0.0606662621187\n",
      "5 41 2.490370750427246 0.0612903201567\n",
      "5 42 2.5204527378082275 0.0616687042804\n",
      "5 43 2.5820610523223877 0.0617238988942\n",
      "5 44 2.5761632919311523 0.0617813850216\n",
      "5 45 2.5843217372894287 0.0624834001433\n",
      "5 46 2.6089296340942383 0.0624830453271\n",
      "5 47 2.618239164352417 0.0618106925011\n",
      "5 48 2.6347315311431885 0.0620373447313\n",
      "5 49 2.66113543510437 0.0620357765528\n",
      "6 12 1.8613669872283936 0.0388306105896\n",
      "6 13 1.8341479301452637 0.038868712922\n",
      "6 14 1.8744699954986572 0.0388764864889\n",
      "6 15 1.8759338855743408 0.0389169034853\n",
      "6 16 1.890728235244751 0.0389169034853\n",
      "6 17 1.8737378120422363 0.0389193532713\n",
      "6 18 1.8860900402069092 0.038783211156\n",
      "6 19 1.9095373153686523 0.0383246526685\n",
      "6 20 1.9086699485778809 0.0380477633239\n",
      "6 21 1.9439210891723633 0.0380210498593\n",
      "6 22 1.9467542171478271 0.0379901174509\n",
      "6 23 1.9469842910766602 0.0381043967703\n",
      "6 24 1.9456944465637207 0.0377172794467\n",
      "6 25 1.979067325592041 0.0376933965727\n",
      "6 26 1.9780099391937256 0.0376085454032\n",
      "6 27 1.9757943153381348 0.0375326932584\n",
      "6 28 1.9765236377716064 0.0375326828474\n",
      "6 29 2.0192365646362305 0.0376677689605\n",
      "6 30 2.0117342472076416 0.0376730393685\n",
      "6 31 2.029064655303955 0.0375810528504\n",
      "6 32 2.024233818054199 0.037708128989\n",
      "6 33 2.044863224029541 0.0376883723771\n",
      "6 34 2.0401744842529297 0.037701998269\n",
      "6 35 2.0201308727264404 0.0377106620963\n",
      "6 36 2.031571626663208 0.03769972596\n",
      "6 37 2.07979416847229 0.0377019623232\n",
      "6 38 2.0543861389160156 0.0376318299611\n",
      "6 39 2.0669517517089844 0.0376743419688\n",
      "6 40 2.0597543716430664 0.0375991799698\n",
      "6 41 2.0882809162139893 0.0378950068897\n",
      "6 42 1.5106031894683838 0.0378645503617\n",
      "6 43 2.130959987640381 0.037938859223\n",
      "6 44 2.1417617797851562 0.0379521270388\n",
      "6 45 2.135551929473877 0.0375591687905\n",
      "6 46 2.1501145362854004 0.0379925937378\n",
      "6 47 2.1533241271972656 0.0380334701588\n",
      "6 48 2.1405036449432373 0.0377813580189\n",
      "6 49 2.1887340545654297 0.0374096494569\n",
      "7 12 1.8058562278747559 0.0377196544813\n",
      "7 13 1.7492825984954834 0.0378873139885\n",
      "7 14 1.7059805393218994 0.0379868011201\n",
      "7 15 1.7737812995910645 0.146935278687\n",
      "7 16 1.8372697830200195 0.148877784216\n",
      "7 17 1.7947454452514648 0.16443329423\n",
      "7 18 1.8212058544158936 0.152253904867\n",
      "7 19 1.8374488353729248 0.152824097537\n",
      "7 20 1.7741930484771729 0.144111514841\n",
      "7 21 1.6377558708190918 0.145899681201\n",
      "7 22 1.8129603862762451 0.147967387174\n",
      "7 23 1.8426322937011719 0.150887582114\n",
      "7 24 1.8448681831359863 0.152904274966\n",
      "7 25 1.833862066268921 0.174502981472\n",
      "7 26 1.774263620376587 0.179268461809\n",
      "7 27 1.882575511932373 0.224038062646\n",
      "7 28 1.793398141860962 0.212095456731\n",
      "7 29 1.8698785305023193 0.934313825526\n",
      "7 30 1.850651502609253 1.05590828316\n",
      "7 31 1.8704850673675537 0.981378581455\n",
      "7 32 1.8525707721710205 0.950428310326\n",
      "7 33 1.8512110710144043 2.33583936717\n",
      "7 34 1.888812780380249 3.44004821237\n",
      "7 35 1.8894636631011963 2.78825941996\n",
      "7 36 1.8901801109313965 3.08259936704\n",
      "7 37 1.9197187423706055 3.31538521842\n",
      "7 38 1.7972979545593262 3.14808674099\n",
      "7 39 1.8883137702941895 2.92109135916\n",
      "7 40 1.8716039657592773 3.12926353237\n",
      "7 41 1.6435906887054443 3.13759963642\n",
      "7 42 1.4593760967254639 3.32397527322\n",
      "7 43 1.9036643505096436 3.17832578227\n",
      "7 44 1.9080443382263184 3.25491794863\n",
      "7 45 1.928229570388794 3.01763105705\n",
      "7 46 1.9395244121551514 2.79159068454\n",
      "7 47 1.9354221820831299 2.93498622403\n",
      "7 48 1.8658418655395508 2.60330123107\n",
      "7 49 1.9275398254394531 2.41717582757\n",
      "8 12 1.7917726039886475 0.157643682652\n",
      "8 13 1.7956550121307373 0.157414328019\n",
      "8 14 1.780505657196045 0.141521731722\n",
      "8 15 1.8082811832427979 0.14148967844\n",
      "8 16 1.8352975845336914 0.137017820073\n",
      "8 17 1.8048737049102783 0.129441699922\n",
      "8 18 1.8206591606140137 0.126962186123\n",
      "8 19 1.802445888519287 0.124774845189\n",
      "8 20 1.8382313251495361 0.125158948178\n",
      "8 21 1.8623967170715332 0.124765338598\n",
      "8 22 1.8242740631103516 0.124276802318\n",
      "8 23 1.8224802017211914 0.117438363097\n",
      "8 24 1.820136547088623 0.116079564975\n",
      "8 25 1.844686508178711 0.115825095628\n",
      "8 26 1.8527076244354248 0.109838053001\n",
      "8 27 1.8424086570739746 0.107894840117\n",
      "8 28 1.8738610744476318 0.106046051991\n",
      "8 29 1.866689920425415 0.102472184704\n",
      "8 30 1.8673105239868164 0.0978835938521\n",
      "8 31 1.8292598724365234 0.0951456470141\n",
      "8 32 1.839298963546753 0.0886907555867\n",
      "8 33 1.8849749565124512 0.0871440001774\n",
      "8 34 1.861957311630249 0.0829827772558\n",
      "8 35 1.8524596691131592 0.0822715326318\n",
      "8 36 1.2527751922607422 0.0822852031777\n",
      "8 37 1.7178471088409424 0.0809027498544\n",
      "8 38 1.8421525955200195 0.0770100996917\n",
      "8 39 1.8371365070343018 0.0761081265695\n",
      "8 40 1.8755779266357422 0.0733559798287\n",
      "8 41 1.8949000835418701 0.071131845951\n",
      "8 42 1.9208242893218994 0.0713266285542\n",
      "8 43 1.943347692489624 0.0707745191608\n",
      "8 44 1.87646484375 0.0700636844702\n",
      "8 45 1.9377961158752441 0.0700168147739\n",
      "8 46 1.8439064025878906 0.069242768489\n",
      "8 47 1.3362455368041992 0.0682962603645\n",
      "8 48 1.8102078437805176 0.0673005764221\n",
      "8 49 1.9268074035644531 0.0661583071897\n",
      "9 12 2.703286647796631 0.0378419193783\n",
      "9 13 2.6991467475891113 0.0379568261101\n",
      "9 14 2.7595596313476562 0.0382661419721\n",
      "9 15 2.7347970008850098 0.0382913143886\n",
      "9 16 2.9440205097198486 0.0382917092314\n",
      "9 17 2.9673008918762207 0.0382923014398\n",
      "9 18 3.211975336074829 0.0383341270018\n",
      "9 19 2.825056791305542 0.0385793808938\n",
      "9 20 3.100658416748047 0.0385663926828\n",
      "9 21 2.9167966842651367 0.0388500533966\n",
      "9 22 2.8536717891693115 0.0389954458378\n",
      "9 23 2.957340955734253 0.039162455225\n",
      "9 24 2.9458508491516113 0.0393809463711\n",
      "9 25 2.929429531097412 0.039361027552\n",
      "9 26 3.1412956714630127 0.0389657224491\n",
      "9 27 3.0449609756469727 0.038422341702\n",
      "9 28 3.0707414150238037 0.0386532611434\n",
      "9 29 3.079822063446045 0.0382130696049\n",
      "9 30 3.040347099304199 0.0384008906095\n",
      "9 31 3.2159368991851807 0.0381993503955\n",
      "9 32 3.0336761474609375 0.0384426268503\n",
      "9 33 3.004556894302368 0.0382898880863\n",
      "9 34 2.966946601867676 0.0381647433713\n",
      "9 35 3.0738120079040527 0.0381692861012\n",
      "9 36 3.081158399581909 0.0381711657508\n",
      "9 37 2.9669065475463867 0.0381741355986\n",
      "9 38 2.9914793968200684 0.0377383239865\n",
      "9 39 2.994619607925415 0.0376306364531\n",
      "9 40 3.013355255126953 0.0378150627832\n",
      "9 41 2.2513303756713867 0.0379557634747\n",
      "9 42 3.068652391433716 0.0380246978448\n",
      "9 43 3.043043613433838 0.0381076270022\n",
      "9 44 3.083862781524658 0.0382398983301\n",
      "9 45 2.962200403213501 0.0382701587689\n",
      "9 46 3.1111197471618652 0.0381463713347\n",
      "9 47 3.156287670135498 0.0383210532182\n",
      "9 48 3.1244301795959473 0.0386271118303\n",
      "9 49 3.1681761741638184 0.0380184807534\n",
      "best regressor 0 best cn 25 0.0360109032812\n"
     ]
    }
   ],
   "source": [
    "cur_time = time.time()\n",
    "best_cn = 0\n",
    "best_val_mse = 1\n",
    "best_regressor = None\n",
    "#regressor\n",
    "for i in range(10):\n",
    "    #cn\n",
    "    for j in range(12, 50):\n",
    "        mses = []\n",
    "        cn = j \n",
    "        pca = PCA(n_components=cn) \n",
    "        pca.fit(merged_X) \n",
    "        X_new = pca.transform(merged_X)\n",
    "        for k in range(cn):\n",
    "            col = X_new[:, k]\n",
    "            m = np.mean(col)\n",
    "            s = np.std(col)\n",
    "            col = (col-m)/s\n",
    "            maxv = np.max(col)\n",
    "            minv = np.min(col)\n",
    "            col = (col-minv)/(maxv-minv)\n",
    "            X_new[:, k] = col\n",
    "        trainX = X_new[:500]\n",
    "        test1X = X_new[500:600]\n",
    "        test2X = X_new[600:]\n",
    "        mses = []\n",
    "        #random state\n",
    "        for k in range(0, 100):\n",
    "            trX, vaX, tr_y, va_y = train_test_split(trainX, train_y, test_size=0.33, random_state=k)\n",
    "            regressor = Regressor(i)\n",
    "            regressor.fit(trX, tr_y)\n",
    "            va_p = regressor.predict(vaX)\n",
    "            mse = MSE_np(va_y, va_p)\n",
    "            mses.append(mse)\n",
    "        mse = np.mean(mses)\n",
    "        if mse < best_val_mse:\n",
    "            best_cn = j\n",
    "            best_regressor = i\n",
    "            best_val_mse = mse\n",
    "        print(i, j, time.time()-cur_time, mse)\n",
    "        cur_time = time.time()\n",
    "print(\"best regressor\", best_regressor, \"best cn\", best_cn, best_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
