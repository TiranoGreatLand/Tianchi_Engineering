{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "test1_df = pd.read_excel(\"data/testA.xlsx\")\n",
    "test2_df = pd.read_excel(\"data/testB.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_df[train_df.columns[-1]]\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 5954) (799,)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_y>1.8]\n",
    "train_y = train_y[train_y>1.8]\n",
    "print(train_df.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_column = test1_df.columns\n",
    "train_df = train_df[new_column]\n",
    "train_id = train_df['ID']\n",
    "test1_id = test1_df['ID']\n",
    "test2_id = test2_df['ID']\n",
    "train_df.drop(['ID'], axis=1, inplace=True)\n",
    "test1_df.drop(['ID'], axis=1, inplace=True)\n",
    "test2_df.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1777 40 629 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = train_df.columns\n",
    "dts = train_df.dtypes\n",
    "drop_names = []\n",
    "year = []\n",
    "ints = []\n",
    "objs = []\n",
    "ratio = 0.1\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    tp = dts[i]\n",
    "    trd = train_df[n]\n",
    "    ted = test1_df[n]\n",
    "    if 'object' == str(tp):\n",
    "        objs.append(n)\n",
    "    else:\n",
    "        misstr = np.sum(trd.isnull())/799\n",
    "        misste = np.sum(ted.isnull())/300\n",
    "        if np.abs(misstr-misste) > ratio:\n",
    "            drop_names.append(n)\n",
    "        else:\n",
    "            trrd = trd[trd.notnull()].values\n",
    "            terd = ted[ted.notnull()].values\n",
    "            if len(trrd) == 0 or len(terd) == 0:\n",
    "                drop_names.append(n)\n",
    "                continue\n",
    "            if (str(trrd[0])[:4] == '2017' and str(trrd[700])[:4] == '2017') or (str(trrd[0])[:4] == '2016' and str(trrd[700])[:4] == '2016'):\n",
    "                    year.append(n)\n",
    "            elif 'int' in str(tp):\n",
    "                ints.append(n)\n",
    "            else:\n",
    "                m1 = np.mean(trrd)\n",
    "                s1 = np.std(trrd)\n",
    "                m2 = np.mean(terd)\n",
    "                s2 = np.std(terd)\n",
    "                if np.abs(m1-m2)>ratio*np.abs(m1) and np.abs(s1-s2)>ratio*np.abs(s1):\n",
    "                    drop_names.append(n)\n",
    "print(len(drop_names),len(year), len(ints), len(objs))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(drop_names, axis=1, inplace=True)\n",
    "test1_df.drop(drop_names, axis=1, inplace=True)\n",
    "test2_df.drop(drop_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = pd.concat([train_df, test1_df, test2_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_X[objs].isnull().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    }
   ],
   "source": [
    "ints += objs\n",
    "print(len(ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 244 277 40\n"
     ]
    }
   ],
   "source": [
    "remains1 = []\n",
    "remains2 = []\n",
    "tobedrop = []\n",
    "\n",
    "for n in ints:\n",
    "    lu1 = len(train_df[n].unique())\n",
    "    lu2 = len(df_X[n].unique())\n",
    "    if lu1 < 15 and lu1 > 1:\n",
    "        remains1.append(n)\n",
    "    if lu2 < 15 and lu2 > 1:\n",
    "        remains2.append(n)\n",
    "    if lu1 != lu2:\n",
    "        tobedrop.append(n)\n",
    "    \n",
    "print(len(remains1), len(remains2), len(tobedrop), len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "toberemain = list(set(remains1) & set(remains2) - set(tobedrop))\n",
    "print(len(toberemain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic:dict):\n",
    "    ''' 将字典转化为列表 '''\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "def LastRemainJudge(column):\n",
    "    unique = set(column)\n",
    "    uf = {}\n",
    "    for u in unique:\n",
    "        uf[u] = 0\n",
    "    for c in column:\n",
    "        uf[c] += 1\n",
    "    sl = sorted(dict2list(uf), key = lambda x:x[1], reverse=True)\n",
    "    x = sl[0][1]/len(column)\n",
    "    sl = np.array(sl)\n",
    "    if x < 0.8:\n",
    "        #print(sl[:, 1]/len(column))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 53 53\n"
     ]
    }
   ],
   "source": [
    "lm1 = []\n",
    "lm2 = []\n",
    "for n in toberemain:\n",
    "    if LastRemainJudge(train_df[n]):\n",
    "        lm1.append(n)\n",
    "    if LastRemainJudge(df_X[n]):\n",
    "        lm2.append(n)\n",
    "print(len(lm1), len(lm2), len(set(lm1)&set(lm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "3646\n",
      "(1511, 3646) (1511, 53)\n"
     ]
    }
   ],
   "source": [
    "names = df_X.columns\n",
    "dts = df_X.dtypes\n",
    "dfx_float_n = []\n",
    "dfx_onehot_n = list(set(lm1) & set(lm2))\n",
    "print(len(dfx_onehot_n))\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    d = dts[i]\n",
    "    if 'float' in str(d):\n",
    "        dfx_float_n.append(n)\n",
    "print(len(dfx_float_n))\n",
    "dfx_float = df_X[dfx_float_n]\n",
    "dfx_onehot = df_X[dfx_onehot_n]\n",
    "print(dfx_float.shape, dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['210X24', '210X205', '210X213', '210X215', '220X71', '300X2', '300X3', '300X4', '300X6', '300X7', '300X9', '300X10', '300X13', '300X14', '300X20', '311X6', '311X7', '311X20', '311X22', '311X55', '311X56', '311X59', '311X60', '311X78', '311X79', '311X163', '311X164', '311X170', '311X171', '400X7', '400X9', '400X25', '400X27', '400X60', '400X61', '400X64', '400X65', '400X83', '400X84', '400X168', '400X169', '400X219', '400X220', '420X186', '520X148', '520X152', '520X171']\n"
     ]
    }
   ],
   "source": [
    "floatyear = []\n",
    "for n in dfx_float.columns:\n",
    "    c = dfx_float[n]\n",
    "    r = c[c.notnull()].astype(np.int64).values\n",
    "    if (str(r[0])[:4] == '2017' and str(r[-1])[:4] == '2017') or (str(r[0])[:4] == '2016' and str(r[-1])[:4] == '2016'):\n",
    "        floatyear.append(n)\n",
    "print(floatyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2444: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer(indexer, value)\n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2424: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210X24 1 1 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210X213 4 3 1 0\n",
      "220X71 1 1 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300X2 45 27 9 9\n",
      "300X3 73 50 9 14\n",
      "300X4 140 95 17 28\n",
      "300X6 1 1 0 0\n",
      "300X7 44 29 9 6\n",
      "300X9 13 9 3 1\n",
      "300X10 15 10 2 3\n",
      "300X13 2 1 0 1\n",
      "300X14 6 3 2 1\n",
      "311X6 58 28 11 19\n",
      "311X7 194 111 41 42\n",
      "311X20 177 103 34 40\n",
      "311X55 35 18 12 5\n",
      "311X56 40 24 4 12\n",
      "311X59 13 9 2 2\n",
      "311X60 39 23 9 7\n",
      "311X163 2 0 2 0\n",
      "311X164 8 6 1 1\n",
      "311X170 1 1 0 0\n",
      "311X171 18 13 0 5\n",
      "400X7 1 1 0 0\n",
      "400X9 1 0 1 0\n",
      "400X25 2 2 0 0\n",
      "400X60 1 1 0 0\n",
      "400X64 1 0 1 0\n",
      "400X83 1 0 1 0\n",
      "400X169 1 1 0 0\n",
      "520X152 1 1 0 0\n"
     ]
    }
   ],
   "source": [
    "dfxt = dfx_float[floatyear]\n",
    "for n in dfxt.columns:\n",
    "    x = np.sum(dfxt[n].isnull())\n",
    "    if x > 0:\n",
    "        c = dfxt[n]\n",
    "        x1 = np.sum(dfxt[n][:799].isnull())\n",
    "        if x1 > 0:\n",
    "            dfxt[:799][c[:799].isnull()] = np.mean(c[:799][c[:799].notnull()])\n",
    "        x2 = np.sum(dfxt[n][799:1099].isnull())\n",
    "        if x2 > 0:\n",
    "            dfxt[799:1099][c[799:1099].isnull()] = np.mean(c[799:1099][c[799:1099].notnull()])\n",
    "        x3 = np.sum(dfxt[n][1099:].isnull())\n",
    "        if x3 > 0:\n",
    "            dfxt[1099:][c[1099:].isnull()] = np.mean(c[1099:][c[1099:].notnull()])\n",
    "        print(n, x, x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "dfx_year = df_X[year]\n",
    "print(np.sum(dfx_year.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520X148 1 0 0 1\n"
     ]
    }
   ],
   "source": [
    "for n in dfx_year.columns:\n",
    "    c = dfx_year[n]\n",
    "    x = np.sum(c.isnull())\n",
    "    if x > 0:\n",
    "        x1 = np.sum(c[:799].isnull())\n",
    "        x2 = np.sum(c[799:1099].isnull())\n",
    "        x3 = np.sum(c[1099:].isnull())\n",
    "        c = dfx_year[n]\n",
    "        dfx_year[1099:][c[1099:].isnull()] = np.mean(c[1099:][c[1099:].notnull()])\n",
    "        print(n, x, x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(dfxt.isnull().values), np.sum(dfx_year.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 3599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfx_float.drop(floatyear, axis=1, inplace=True)\n",
    "print(dfx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 87)\n"
     ]
    }
   ],
   "source": [
    "dfx_days = pd.concat([dfx_year, dfxt], axis=1)\n",
    "print(dfx_days.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 2)\n"
     ]
    }
   ],
   "source": [
    "c = copy.copy(dfx_days['520X148'])\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 85)\n"
     ]
    }
   ],
   "source": [
    "dfx_days.drop(['520X148'], axis=1, inplace=True)\n",
    "print(dfx_days.shape)\n",
    "dfx_days['520X148'] = c.values[:, 0]\n",
    "dfx_days['520X148X1'] = c.values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 210X204 int64\n",
      "1 220X67 int64\n",
      "2 220X75 int64\n",
      "3 220X79 int64\n",
      "4 220X83 int64\n",
      "5 220X87 int64\n",
      "6 220X91 int64\n",
      "7 220X95 int64\n",
      "8 310X56 int64\n",
      "9 310X60 int64\n",
      "10 310X64 int64\n",
      "11 310X68 int64\n",
      "12 310X72 int64\n",
      "13 310X76 int64\n",
      "14 310X80 int64\n",
      "15 310X84 int64\n",
      "16 360X710 int64\n",
      "17 360X711 int64\n",
      "18 360X1287 int64\n",
      "19 360X1291 int64\n",
      "20 360X1292 int64\n",
      "21 360X1293 int64\n",
      "22 420X7 int64\n",
      "23 420X9 int64\n",
      "24 420X25 int64\n",
      "25 420X27 int64\n",
      "26 520X173 int64\n",
      "27 520X248 int64\n",
      "28 520X250 int64\n",
      "29 520X346 int64\n",
      "30 520X348 int64\n",
      "31 520X354 int64\n",
      "32 520X356 int64\n",
      "33 750X710 int64\n",
      "34 750X711 int64\n",
      "35 750X1287 int64\n",
      "36 750X1291 int64\n",
      "37 750X1292 int64\n",
      "38 750X1293 int64\n",
      "39 210X24 int64\n",
      "40 210X205 int64\n",
      "41 210X213 int64\n",
      "42 210X215 int64\n",
      "43 220X71 int64\n",
      "44 300X2 int64\n",
      "45 300X3 int64\n",
      "46 300X4 int64\n",
      "47 300X6 int64\n",
      "48 300X7 int64\n",
      "49 300X9 int64\n",
      "50 300X10 int64\n",
      "51 300X13 int64\n",
      "52 300X14 int64\n",
      "53 300X20 int64\n",
      "54 311X6 int64\n",
      "55 311X7 int64\n",
      "56 311X20 int64\n",
      "57 311X22 int64\n",
      "58 311X55 int64\n",
      "59 311X56 int64\n",
      "60 311X59 int64\n",
      "61 311X60 int64\n",
      "62 311X78 int64\n",
      "63 311X79 int64\n",
      "64 311X163 int64\n",
      "65 311X164 int64\n",
      "66 311X170 int64\n",
      "67 311X171 int64\n",
      "68 400X7 int64\n",
      "69 400X9 int64\n",
      "70 400X25 int64\n",
      "71 400X27 int64\n",
      "72 400X60 int64\n",
      "73 400X61 int64\n",
      "74 400X64 int64\n",
      "75 400X65 int64\n",
      "76 400X83 int64\n",
      "77 400X84 int64\n",
      "78 400X168 int64\n",
      "79 400X169 int64\n",
      "80 400X219 int64\n",
      "81 400X220 int64\n",
      "82 420X186 int64\n",
      "83 520X152 int64\n",
      "84 520X171 int64\n",
      "85 520X148 int64\n",
      "86 520X148X1 int64\n"
     ]
    }
   ],
   "source": [
    "#convert type of ime columns into int so that the length is true\n",
    "names = dfx_days.columns\n",
    "dtypes = dfx_days.dtypes\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    if 'int' not in str(dtypes[i]):\n",
    "        dfx_days[n] = dfx_days[n].astype(np.int64)\n",
    "    print(i, n, dfx_days[n].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copydfxday = copy.copy(dfx_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "0 87 5 100000\n",
      "1 92 0 1\n",
      "2 92 0 1\n",
      "3 92 0 1\n",
      "4 92 0 1\n",
      "5 92 0 1\n",
      "6 92 0 1\n",
      "7 92 0 1\n",
      "8 92 0 1\n",
      "9 92 0 1\n",
      "10 92 0 1\n",
      "11 92 0 1\n",
      "12 92 0 1\n",
      "13 92 0 1\n",
      "14 92 0 1\n",
      "15 92 0 1\n",
      "16 69 23 100000000000000000000000\n",
      "17 69 23 100000000000000000000000\n",
      "18 70 22 10000000000000000000000\n",
      "19 70 22 10000000000000000000000\n",
      "20 70 22 10000000000000000000000\n",
      "21 70 22 10000000000000000000000\n",
      "22 85 7 10000000\n",
      "23 85 7 10000000\n",
      "24 86 6 1000000\n",
      "25 86 6 1000000\n",
      "26 87 5 100000\n",
      "27 87 5 100000\n",
      "28 87 5 100000\n",
      "29 87 5 100000\n",
      "30 87 5 100000\n",
      "31 87 5 100000\n",
      "32 87 5 100000\n",
      "33 69 23 100000000000000000000000\n",
      "34 69 23 100000000000000000000000\n",
      "35 70 22 10000000000000000000000\n",
      "36 70 22 10000000000000000000000\n",
      "37 70 22 10000000000000000000000\n",
      "38 70 22 10000000000000000000000\n",
      "39 86 6 1000000\n",
      "40 87 5 100000\n",
      "41 87 5 100000\n",
      "42 87 5 100000\n",
      "43 92 0 1\n",
      "44 85 7 10000000\n",
      "45 85 7 10000000\n",
      "46 85 7 10000000\n",
      "47 85 7 10000000\n",
      "48 85 7 10000000\n",
      "49 85 7 10000000\n",
      "50 86 6 1000000\n",
      "51 86 6 1000000\n",
      "52 86 6 1000000\n",
      "53 86 6 1000000\n",
      "54 85 7 10000000\n",
      "55 85 7 10000000\n",
      "56 86 6 1000000\n",
      "57 86 6 1000000\n",
      "58 86 6 1000000\n",
      "59 86 6 1000000\n",
      "60 86 6 1000000\n",
      "61 86 6 1000000\n",
      "62 86 6 1000000\n",
      "63 86 6 1000000\n",
      "64 87 5 100000\n",
      "65 87 5 100000\n",
      "66 87 5 100000\n",
      "67 87 5 100000\n",
      "68 85 7 10000000\n",
      "69 85 7 10000000\n",
      "70 86 6 1000000\n",
      "71 86 6 1000000\n",
      "72 86 6 1000000\n",
      "73 86 6 1000000\n",
      "74 86 6 1000000\n",
      "75 86 6 1000000\n",
      "76 86 6 1000000\n",
      "77 86 6 1000000\n",
      "78 87 5 100000\n",
      "79 87 5 100000\n",
      "80 87 5 100000\n",
      "81 87 5 100000\n",
      "82 87 5 100000\n",
      "83 87 5 100000\n",
      "84 87 5 100000\n",
      "85 87 5 100000\n",
      "86 89 3 1000\n",
      "['220X67']\n"
     ]
    }
   ],
   "source": [
    "day_n = dfx_days.columns\n",
    "standardcolumn = copy.copy(dfx_days[day_n[1]])\n",
    "standardlen = len(str(standardcolumn[0]))\n",
    "print(standardlen)\n",
    "drop_names = []\n",
    "for i in range(len(day_n)):\n",
    "    #if i == 1:\n",
    "    #    print(i, \"standard\")\n",
    "    #    continue\n",
    "    l = len(str(dfx_days[day_n[i]][0]))\n",
    "    bias = standardlen - l\n",
    "    b10 = 1\n",
    "    if bias > 0:\n",
    "        for j in range(bias):\n",
    "            b10 *= 10\n",
    "    elif bias < 0:\n",
    "        for j in range(-bias):\n",
    "            b10 /= 10\n",
    "    print(i, l, bias, b10)\n",
    "    if b10 != 1:\n",
    "        dfx_days[day_n[i]] *= b10\n",
    "    dfx_days[day_n[i]] = dfx_days[day_n[i]] - standardcolumn\n",
    "    if np.sum(dfx_days[day_n[i]]) == 0:\n",
    "        drop_names.append(day_n[i])\n",
    "print(drop_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 86)\n"
     ]
    }
   ],
   "source": [
    "dfx_days.drop(drop_names, axis=1, inplace=True)\n",
    "print(dfx_days.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize time\n",
    "names = dfx_days.columns\n",
    "for n in names:\n",
    "    c = dfx_days[n]\n",
    "    tmpm = np.mean(c)\n",
    "    tmps = np.std(c)\n",
    "    dfx_days[n] = (dfx_days[n] - tmpm) / tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360X710 47\n",
      "360X711 47\n",
      "360X1287 47\n",
      "360X1291 47\n",
      "360X1292 47\n",
      "360X1293 47\n",
      "750X710 45\n",
      "750X711 45\n",
      "750X1287 45\n",
      "750X1291 45\n",
      "750X1292 45\n",
      "750X1293 45\n",
      "['360X710', '360X711', '360X1287', '360X1291', '360X1292', '360X1293', '750X710', '750X711', '750X1287', '750X1291', '750X1292', '750X1293']\n"
     ]
    }
   ],
   "source": [
    "tooshort = []\n",
    "for n in names:\n",
    "    l = len(set(dfx_days[n]))\n",
    "    if l < 100:\n",
    "        print(n, l)\n",
    "        tooshort.append(n)\n",
    "print(tooshort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 65)\n"
     ]
    }
   ],
   "source": [
    "dfxoh = pd.concat([dfx_onehot, copydfxday[tooshort]], axis=1)\n",
    "print(dfxoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 74)\n",
      "(1511, 76)\n",
      "(1511, 79)\n",
      "(1511, 85)\n",
      "(1511, 87)\n",
      "(1511, 90)\n",
      "(1511, 96)\n",
      "(1511, 100)\n",
      "(1511, 104)\n",
      "(1511, 106)\n",
      "(1511, 113)\n",
      "(1511, 115)\n",
      "(1511, 124)\n",
      "(1511, 131)\n",
      "(1511, 134)\n",
      "(1511, 138)\n",
      "(1511, 140)\n",
      "(1511, 144)\n",
      "(1511, 148)\n",
      "(1511, 152)\n",
      "(1511, 155)\n",
      "(1511, 157)\n",
      "(1511, 161)\n",
      "(1511, 163)\n",
      "(1511, 168)\n",
      "(1511, 170)\n",
      "(1511, 173)\n",
      "(1511, 178)\n",
      "(1511, 181)\n",
      "(1511, 189)\n",
      "(1511, 194)\n",
      "(1511, 196)\n",
      "(1511, 198)\n",
      "(1511, 200)\n",
      "(1511, 205)\n",
      "(1511, 210)\n",
      "(1511, 212)\n",
      "(1511, 214)\n",
      "(1511, 216)\n",
      "(1511, 218)\n",
      "(1511, 220)\n",
      "(1511, 230)\n",
      "(1511, 232)\n",
      "(1511, 235)\n",
      "(1511, 238)\n",
      "(1511, 246)\n",
      "(1511, 248)\n",
      "(1511, 255)\n",
      "(1511, 261)\n",
      "(1511, 265)\n",
      "(1511, 269)\n",
      "(1511, 271)\n",
      "(1511, 275)\n",
      "(1511, 322)\n",
      "(1511, 369)\n",
      "(1511, 416)\n",
      "(1511, 463)\n",
      "(1511, 510)\n",
      "(1511, 557)\n",
      "(1511, 602)\n",
      "(1511, 647)\n",
      "(1511, 692)\n",
      "(1511, 737)\n",
      "(1511, 782)\n",
      "(1511, 827)\n"
     ]
    }
   ],
   "source": [
    "# make onehots onehot\n",
    "ohnames = dfxoh.columns\n",
    "for i in range(len(ohnames)):\n",
    "    n = ohnames[i]\n",
    "    tmp = pd.get_dummies(dfxoh[n], prefix='onehot_'+str(i))\n",
    "    dfxoh = pd.concat([dfxoh, tmp], axis=1)\n",
    "    print(dfxoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 762)\n"
     ]
    }
   ],
   "source": [
    "dfxoh.drop(ohnames, axis=1, inplace=True)\n",
    "print(dfxoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_names = []\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    x = np.sum(dfx_float[n].isnull())\n",
    "    if x > 500:\n",
    "        drop_names.append(n)\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1679 1622\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "stds = []\n",
    "drop_names = []\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    c = dfx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    means.append(tmpm)\n",
    "    stds.append(tmps)\n",
    "    if tmps == 0:\n",
    "        drop_names.append(n)\n",
    "print(len(set(means)), len(set(stds)))\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1511, 3329)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx_float.drop(drop_names, axis=1, inplace=True)\n",
    "dfx_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    }
   ],
   "source": [
    "# not move sames first, fill nan\n",
    "names = dfx_float.columns\n",
    "added = set()\n",
    "sames = []\n",
    "for i in range(len(names)):\n",
    "    tmpsl = []\n",
    "    tmpsl.append(i)\n",
    "    for j in range(i+1, len(names)):\n",
    "        if means[i] == means[j] and stds[i] == stds[j]:\n",
    "            if i not in added:\n",
    "                added.add(i)\n",
    "            if j not in added:\n",
    "                added.add(j)\n",
    "                tmpsl.append(j)\n",
    "    if len(tmpsl) > 1:\n",
    "        sames.append(tmpsl)\n",
    "print(len(sames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677\n"
     ]
    }
   ],
   "source": [
    "names = dfx_float.columns\n",
    "drop_names = []\n",
    "for i in sames:\n",
    "    for j in i[1:]:\n",
    "        drop_names.append(names[j])\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 3329)\n",
      "(1511, 1652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(dfx_float.shape)\n",
    "trainx_float = copy.copy(dfx_float)\n",
    "dfx_float.drop(drop_names, axis=1, inplace=True)\n",
    "print(dfx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5088: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# fix first then log\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    c = dfx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    assert tmps>0\n",
    "    dfx_float[n][c.isnull()] = tmpm\n",
    "print(np.sum(dfx_float.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "mid = dfx_float-np.min(dfx_float)+1\n",
    "dfx_log1p = np.log1p(mid)\n",
    "del mid\n",
    "print(np.sum(dfx_log1p.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in dfx_log1p.columns:\n",
    "    c = dfx_log1p[n]\n",
    "    tmpm = np.mean(c)\n",
    "    tmps = np.std(c)\n",
    "    assert tmps > 0\n",
    "    dfx_log1p[n] = (dfx_log1p[n] - tmpm)/tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1511, 2500)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = pd.concat([dfx_log1p, dfxoh, dfx_days], axis=1)\n",
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_raw, y_pred):\n",
    "    return np.mean(np.square(y_raw-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012093681205\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(gamma=0.0001, max_depth=4, objective='reg:linear', subsample=0.85)\n",
    "xgb.fit(dfx[:799].values, train_y.values)\n",
    "test1_pred = xgb.predict(dfx[:799].values)\n",
    "print(MSE(test1_pred, train_y.values))\n",
    "test1_pred = xgb.predict(dfx[800:1100].values)\n",
    "test1_pred = test1_pred.reshape(300)\n",
    "save = pd.DataFrame({'ID':test1_id, 'value':test1_pred})\n",
    "save.to_csv('answer/Synchronous_timeappend_logohtime_xgb_20180126.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
