{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "test1_df = pd.read_excel(\"data/testA.xlsx\")\n",
    "test2_df = pd.read_excel(\"data/testB.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_df[train_df.columns[-1]]\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_column = test1_df.columns\n",
    "train_df = train_df[new_column]\n",
    "train_id = train_df['ID']\n",
    "test1_id = test1_df['ID']\n",
    "test2_id = test2_df['ID']\n",
    "train_df.drop(['ID'], axis=1, inplace=True)\n",
    "test1_df.drop(['ID'], axis=1, inplace=True)\n",
    "test2_df.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# ints or strings\n",
    "ints = []\n",
    "year = []\n",
    "for i in range(len(names)):\n",
    "    if 'int' in str(dts[i]) or 'object' in str(dts[i]):\n",
    "        ints.append(names[i])\n",
    "print(len(ints))\n",
    "\n",
    "for n in ints:\n",
    "    if str(train_df[n][0])[:4] == '2017' and str(test1_df[n][0])[:4] == '2017':\n",
    "        year.append(n)\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = train_df.columns\n",
    "dts = train_df.dtypes\n",
    "drop_names = []\n",
    "year = []\n",
    "ratio = 0.1\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    tp = dts[i]\n",
    "    trd = train_df[n]\n",
    "    ted = test1_df[n]\n",
    "    if 'object' == str(tp):\n",
    "        continue\n",
    "    else:\n",
    "        misstr = np.sum(trd.isnull())/500\n",
    "        misste = np.sum(ted.isnull())/100\n",
    "        if np.abs(misstr-misste) > ratio:\n",
    "            drop_names.append(n)\n",
    "        else:\n",
    "            if 'int' in str(tp):\n",
    "                if str(train_df[n][0])[:4] == '2017' and str(train_df[n][499])[:4] == '2017':\n",
    "                    year.append(n)\n",
    "            else:\n",
    "                trrd = trd[trd.notnull()]\n",
    "                terd = ted[ted.notnull()]\n",
    "                m1 = np.mean(trrd)\n",
    "                s1 = np.std(trrd)\n",
    "                m2 = np.mean(terd)\n",
    "                s2 = np.std(terd)\n",
    "                if np.abs(m1-m2)>ratio*np.abs(m1) and np.abs(s1-s2)>ratio*np.abs(s1):\n",
    "                    drop_names.append(n)\n",
    "print(len(drop_names))\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(drop_names, axis=1, inplace=True)\n",
    "test1_df.drop(drop_names, axis=1, inplace=True)\n",
    "test2_df.drop(drop_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = train_df.columns\n",
    "dfs = train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "# ints or strings\n",
    "ints = []\n",
    "for i in range(len(names)):\n",
    "    if 'int' in str(dfs[i]) or 'object' in str(dfs[i]):\n",
    "        ints.append(names[i])\n",
    "print(len(ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = pd.concat([train_df, test1_df, test2_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_year = df_X[year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 169 229 40\n"
     ]
    }
   ],
   "source": [
    "remains1 = []\n",
    "remains2 = []\n",
    "tobedrop = []\n",
    "\n",
    "for n in ints:\n",
    "    lu1 = len(train_df[n].unique())\n",
    "    lu2 = len(df_X[n].unique())\n",
    "    if lu1 < 10 and lu1 > 1:\n",
    "        remains1.append(n)\n",
    "    if lu2 < 10 and lu2 > 1:\n",
    "        remains2.append(n)\n",
    "    if lu1 != lu2:\n",
    "        tobedrop.append(n)\n",
    "    \n",
    "print(len(remains1), len(remains2), len(tobedrop), len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "toberemain = list(set(remains1) & set(remains2) - set(tobedrop))\n",
    "print(len(toberemain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic:dict):\n",
    "    ''' 将字典转化为列表 '''\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "def LastRemainJudge(column):\n",
    "    unique = set(column)\n",
    "    uf = {}\n",
    "    for u in unique:\n",
    "        uf[u] = 0\n",
    "    for c in column:\n",
    "        uf[c] += 1\n",
    "    sl = sorted(dict2list(uf), key = lambda x:x[1], reverse=True)\n",
    "    x = sl[0][1]/len(column)\n",
    "    sl = np.array(sl)\n",
    "    if x < 0.8:\n",
    "        #print(sl[:, 1]/len(column))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 52 52\n"
     ]
    }
   ],
   "source": [
    "lm1 = []\n",
    "lm2 = []\n",
    "for n in toberemain:\n",
    "    if LastRemainJudge(train_df[n]):\n",
    "        lm1.append(n)\n",
    "    if LastRemainJudge(df_X[n]):\n",
    "        lm2.append(n)\n",
    "print(len(lm1), len(lm2), len(set(lm1)&set(lm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "3097\n",
      "(1512, 3097) (1512, 52)\n"
     ]
    }
   ],
   "source": [
    "names = df_X.columns\n",
    "dts = df_X.dtypes\n",
    "dfx_float_n = []\n",
    "dfx_onehot_n = list(set(lm1) & set(lm2))\n",
    "print(len(dfx_onehot_n))\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    d = dts[i]\n",
    "    if 'float' in str(d):\n",
    "        dfx_float_n.append(n)\n",
    "print(len(dfx_float_n))\n",
    "dfx_float = df_X[dfx_float_n]\n",
    "dfx_onehot = df_X[dfx_onehot_n]\n",
    "print(dfx_float.shape, dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_names = []\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    x = np.sum(dfx_float[n].isnull())\n",
    "    if x > 500:\n",
    "        drop_names.append(n)\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292 1278\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "stds = []\n",
    "drop_names = []\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    c = dfx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    means.append(tmpm)\n",
    "    stds.append(tmps)\n",
    "    if tmps == 0:\n",
    "        drop_names.append(n)\n",
    "print(len(set(means)), len(set(stds)))\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfx_float.drop(drop_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "# not move sames first, fill nan\n",
    "added = set()\n",
    "sames = []\n",
    "for i in range(len(names)):\n",
    "    tmpsl = []\n",
    "    tmpsl.append(i)\n",
    "    for j in range(i+1, len(names)):\n",
    "        if means[i] == means[j] and stds[i] == stds[j]:\n",
    "            if i not in added:\n",
    "                added.add(i)\n",
    "            if j not in added:\n",
    "                added.add(j)\n",
    "                tmpsl.append(j)\n",
    "    if len(tmpsl) > 1:\n",
    "        sames.append(tmpsl)\n",
    "print(len(sames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672\n"
     ]
    }
   ],
   "source": [
    "names = dfx_float.columns\n",
    "drop_names = []\n",
    "for i in sames:\n",
    "    for j in i[1:]:\n",
    "        drop_names.append(names[j])\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 2966)\n"
     ]
    }
   ],
   "source": [
    "print(dfx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 1294)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "trainx_float = copy.copy(dfx_float)\n",
    "trainx_float.drop(drop_names, axis=1, inplace=True)\n",
    "print(trainx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "names = trainx_float.columns\n",
    "for n in names:\n",
    "    c = trainx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    assert tmps>0\n",
    "    trainx_float[n][c.isnull()] = tmpm\n",
    "print(np.sum(trainx_float.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# it shall be that there is only thre lines with nan in log1p\n",
    "mid = trainx_float-np.min(trainx_float)+1\n",
    "trainx_log1p = np.log1p(mid)\n",
    "del mid\n",
    "print(np.sum(trainx_log1p.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in names:\n",
    "    m1 = np.mean(trainx_float[n])\n",
    "    s1 = np.std(trainx_float[n])\n",
    "    assert s1 > 0\n",
    "    trainx_float[n] = (trainx_float[n]-m1)/s1\n",
    "    m2 = np.mean(trainx_log1p[n])\n",
    "    s2 = np.std(trainx_log1p[n])\n",
    "    assert s2 > 0\n",
    "    trainx_log1p[n] = (trainx_log1p[n]-m2)/s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make onehots onehot\n",
    "ohnames = dfx_onehot.columns\n",
    "for i in range(len(ohnames)):\n",
    "    n = ohnames[i]\n",
    "    tmp = pd.get_dummies(dfx_onehot[n], prefix='onehot_'+str(i))\n",
    "    dfx_onehot = pd.concat([dfx_onehot, tmp], axis=1)\n",
    "    #print(dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 200)\n"
     ]
    }
   ],
   "source": [
    "dfx_onehot.drop(ohnames, axis=1, inplace=True)\n",
    "print(dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_float = trainx_float\n",
    "dfx_log1p = trainx_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "year_n = dfx_year.columns\n",
    "standardlen = len(str(dfx_year[year_n[0]][0]))\n",
    "for i in range(1, len(year_n)):\n",
    "    l = len(str(dfx_year[year_n[i]][0]))\n",
    "    bias = standardlen - l\n",
    "    b10 = 1\n",
    "    if bias > 0:\n",
    "        for j in range(bias):\n",
    "            b10 *= 10\n",
    "            #dfx_year[year_n[i]] /= 10\n",
    "    elif bias < 0:\n",
    "        for j in range(-bias):\n",
    "            b10 /= 10\n",
    "            #dfx_year[year_n[i]] *= 10\n",
    "    if b10 != 1:\n",
    "        dfx_year[year_n[i]] *= b10\n",
    "    dfx_year[year_n[i]] = dfx_year[year_n[i]] - dfx_year[year_n[0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_time = (dfx_year - np.mean(dfx_year))/np.std(dfx_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 40)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_time = dfx_time[dfx_time.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 39)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Ck1cgKGV+xwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb16733deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dfx_time.values[:800, 20], train_y.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_raw, y_pred):\n",
    "    r = np.mean(np.square(y_raw-y_pred))\n",
    "    #print(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5, random_state=2018)\n",
    "def get_oof(rgr, xtrain, ytrain, xtest, lenot, lenoe):\n",
    "    oof_train = np.zeros((lenot,))\n",
    "    oof_test = np.zeros((lenoe,))\n",
    "    oof_test_skf = np.empty((5, lenoe))\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(xtrain)):\n",
    "        kf_xtrain = xtrain[train_index]\n",
    "        kf_ytrain = ytrain[train_index]\n",
    "        kf_xtest = xtrain[test_index]\n",
    "        rgr.fit(kf_xtrain, kf_ytrain)\n",
    "        oof_train[test_index] = rgr.predict(kf_xtest)\n",
    "        oof_test_skf[i, : ] = rgr.predict(xtest)\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 1494)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = pd.concat([dfx_log1p, dfx_onehot], axis=1)\n",
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 1533)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfx = pd.concat([dfx, dfx_time], axis=1)\n",
    "ndfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trndfx = ndfx[:800]\n",
    "trndfx = trndfx[train_y>1.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trny = train_y[train_y>1.8]\n",
    "trny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012956001176\n",
      "0.0150168025429\n",
      "0.015843769448\n",
      "0.0131705455574\n",
      "0.0156547362543\n",
      "0.0146185219075\n",
      "0.0158633236506\n",
      "0.0167757342976\n",
      "0.0135966512199\n",
      "0.0145114011405\n",
      "0.0172754119816\n",
      "0.0171190575495\n",
      "0.0105734644657\n",
      "0.0124101902374\n",
      "0.0126557356753\n",
      "0.015217866917\n",
      "0.0167976511115\n",
      "0.0146798482578\n",
      "0.0141277893793\n",
      "0.0172738964178\n",
      "0.0127518392458\n",
      "0.013905636772\n",
      "0.0145157559799\n",
      "0.0154943764592\n",
      "0.0174574300301\n",
      "0.0164373301091\n",
      "0.013905253713\n",
      "0.0148862882576\n",
      "0.0139915444035\n",
      "0.0125284288349\n",
      "0.0139929158424\n",
      "0.0139163575899\n",
      "0.0146356923942\n",
      "0.0156436487755\n",
      "0.0150150257671\n",
      "0.0162272868305\n",
      "0.0142023871309\n",
      "0.0134772090564\n",
      "0.0189895926045\n",
      "0.0177293716459\n",
      "0.0127569953264\n",
      "0.018876079102\n",
      "0.0154266007152\n",
      "0.0147759270755\n",
      "0.0136348156065\n",
      "0.0122414702742\n",
      "0.0165051503477\n",
      "0.0157881905492\n",
      "0.0163351629827\n",
      "0.015429703898\n",
      "0.0144718424726\n",
      "0.0144499678893\n",
      "0.0146097353736\n",
      "0.0147579720675\n",
      "0.0158972966404\n",
      "0.0144523196403\n",
      "0.0143572425903\n",
      "0.0156763162759\n",
      "0.0145365142343\n",
      "0.013556625133\n",
      "0.0178730312302\n",
      "0.0141170712657\n",
      "0.0121557544992\n",
      "0.0146539209454\n",
      "0.0114301368028\n",
      "0.0148380930535\n",
      "0.0160524099077\n",
      "0.0147380216361\n",
      "0.013528250364\n",
      "0.012736675789\n",
      "0.0161659029079\n",
      "0.0148912253086\n",
      "0.0155877142498\n",
      "0.0151190123884\n",
      "0.0132504294566\n",
      "0.0162651360975\n",
      "0.0159365571627\n",
      "0.0164085726504\n",
      "0.0142287764898\n",
      "0.013190264432\n",
      "0.0133937649378\n",
      "0.0128154443499\n",
      "0.01419843848\n",
      "0.015490217044\n",
      "0.01479519621\n",
      "0.0168810250611\n",
      "0.0131937426809\n",
      "0.0146148381914\n",
      "0.0149788609123\n",
      "0.0150138363312\n",
      "0.0152397300042\n",
      "0.0149397558262\n",
      "0.0115532840466\n",
      "0.0169397356983\n",
      "0.0132020317514\n",
      "0.012100008739\n",
      "0.0138202843584\n",
      "0.0116311395662\n",
      "0.01715283479\n",
      "0.0146477582637\n",
      "0.014741465827 0.00162512429795 0.0189895926045 0.0105734644657\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(100):\n",
    "    subxtrain, subxval, subytrain, subyval = train_test_split(trndfx.values, trny.values, test_size=0.2, random_state=i)\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "    xgb.fit(subxtrain, subytrain)\n",
    "    test1_pred = xgb.predict(subxval)\n",
    "    t = MSE(test1_pred, subyval)\n",
    "    results.append(t)\n",
    "print(np.mean(results), np.std(results), np.max(results), np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0135574214126\n",
      "0.0164872261235\n",
      "0.0162525870101\n",
      "0.0214337744511\n",
      "0.0253874904891\n",
      "0.0163909634633\n",
      "0.0169658296069\n",
      "0.0154989624207\n",
      "0.0142551938484\n",
      "0.0140980651021\n",
      "0.0131023609852\n",
      "0.017116023615\n",
      "0.0110168668444\n",
      "0.0141042236556\n",
      "0.0132669091062\n",
      "0.0150043251495\n",
      "0.0251771290681\n",
      "0.0129299274312\n",
      "0.0122980973252\n",
      "0.0247279711981\n",
      "0.0113913543423\n",
      "0.0245754927174\n",
      "0.0148365673404\n",
      "0.0155191793253\n",
      "0.0152708444741\n",
      "0.0163950287949\n",
      "0.0226646010458\n",
      "0.0132511928378\n",
      "0.0227390401291\n",
      "0.013033943196\n",
      "0.0135286906774\n",
      "0.0208047247143\n",
      "0.0125110271558\n",
      "0.0238323786803\n",
      "0.0158291090335\n",
      "0.0159678129237\n",
      "0.0240316998322\n",
      "0.0210864260986\n",
      "0.01725108176\n",
      "0.0146208094491\n",
      "0.0140139392389\n",
      "0.0160940329359\n",
      "0.015002615111\n",
      "0.0151080626849\n",
      "0.0145854730014\n",
      "0.0110666709734\n",
      "0.0164601056893\n",
      "0.0243838124178\n",
      "0.0150882340591\n",
      "0.0129399163975\n",
      "0.01491601412\n",
      "0.0234373903215\n",
      "0.014000310685\n",
      "0.0140418323898\n",
      "0.0214111215984\n",
      "0.0239153520837\n",
      "0.0147230896859\n",
      "0.0175141975434\n",
      "0.017402327481\n",
      "0.0135053632946\n",
      "0.0157099977967\n",
      "0.014759646247\n",
      "0.0142877182763\n",
      "0.0241371362159\n",
      "0.0134825018877\n",
      "0.0135423128965\n",
      "0.0179007501693\n",
      "0.0201764684239\n",
      "0.0171708367748\n",
      "0.0144461159759\n",
      "0.0160240516412\n",
      "0.0119936871641\n",
      "0.0146977408911\n",
      "0.0238705932627\n",
      "0.0123682803737\n",
      "0.0154482012205\n",
      "0.0153113890921\n",
      "0.0170663745311\n",
      "0.0156239000942\n",
      "0.0163037319962\n",
      "0.0139670614342\n",
      "0.0216477672634\n",
      "0.0207590847104\n",
      "0.0167459322459\n",
      "0.0143517979301\n",
      "0.0125838913701\n",
      "0.0163678692756\n",
      "0.0181551106826\n",
      "0.014226689867\n",
      "0.015114498617\n",
      "0.0140764542946\n",
      "0.0152219898471\n",
      "0.0151513467673\n",
      "0.0196442988617\n",
      "0.0215728059557\n",
      "0.0235174704833\n",
      "0.0149480704786\n",
      "0.0124146236477\n",
      "0.0245555321156\n",
      "0.0144535420512\n",
      "0.0167161948738 0.00383721889742 0.0253874904891 0.0110168668444\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(100):\n",
    "    subxtrain, subxval, subytrain, subyval = train_test_split(ndfx[:800].values, train_y.values, test_size=0.2, random_state=i)\n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "    xgb.fit(subxtrain, subytrain)\n",
    "    test1_pred = xgb.predict(subxval)\n",
    "    t = MSE(test1_pred, subyval)\n",
    "    results.append(t)\n",
    "print(np.mean(results), np.std(results), np.max(results), np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop one low point and first time 0.014741465827 0.00162512429795 0.0189895926045 0.0105734644657\n",
    "# drop first time                   0.0167161948738 0.00383721889742 0.0253874904891 0.0110168668444\n",
    "# drop one low point                0.014741465827 0.00162512429795 0.0189895926045 0.0105734644657\n",
    "# no drop                           0.0167161948738 0.00383721889742 0.0253874904891 0.0110168668444 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00146086023566 0.0128567520904\n",
      "1\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00282183987351 0.0141974493677\n",
      "2\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000817409294922 0.0143166110715\n",
      "3\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000940050607208 0.0129356805313\n",
      "4\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00142270923584 0.0160145394252\n",
      "5\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00142029589041 0.0142416098444\n",
      "6\n",
      "{'colsample_bytree': 1, 'gamma': 0.0001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00232924441936 0.0160137860126\n",
      "7\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000856564004608 0.0160179449751\n",
      "8\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00269804099582 0.012384124207\n",
      "9\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.000937840602161 0.0129667060117\n",
      "10\n",
      "{'colsample_bytree': 0.75, 'gamma': 0, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00272371062793 0.018396066327\n",
      "11\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.0009503731405 0.0160494080556\n",
      "12\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000934767949254 0.0108480031717\n",
      "13\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00109252667922 0.0116626884352\n",
      "14\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00263711175682 0.0124691190762\n",
      "15\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.000972363570801 0.013226842732\n",
      "16\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 2, 'subsample': 0.85}\n",
      "0.00290640350909 0.0157660420199\n",
      "17\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00117736469696 0.0145844564658\n",
      "18\n",
      "{'colsample_bytree': 1, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00112935682768 0.0138718271255\n",
      "19\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.0024092144569 0.0147678498107\n",
      "20\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000931140548841 0.0119944494884\n",
      "21\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000999095538193 0.0140760652635\n",
      "22\n",
      "{'colsample_bytree': 0.75, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00133173745225 0.0148124531505\n",
      "23\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00252555919381 0.0148705161335\n",
      "24\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.0026294229527 0.0175049602387\n",
      "25\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00106381221583 0.0156187356239\n",
      "26\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00266216701477 0.0136161467607\n",
      "27\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 2, 'subsample': 0.7}\n",
      "0.00105996093646 0.0158860964926\n",
      "28\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00243980779754 0.0139865603864\n",
      "29\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00106775770069 0.0128595031016\n",
      "30\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.000959780024473 0.0143516000693\n",
      "31\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00103881798068 0.0140271848622\n",
      "32\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00270346669804 0.0132417954649\n",
      "33\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00155006170768 0.0154470423842\n",
      "34\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00103056701957 0.0151282823073\n",
      "35\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00103278748452 0.0188733457938\n",
      "36\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00172713910007 0.0130138642077\n",
      "37\n",
      "{'colsample_bytree': 0.5, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000887989180195 0.0122009755818\n",
      "38\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00107480439124 0.0178433971608\n",
      "39\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 2, 'subsample': 0.85}\n",
      "0.00252192592071 0.0170331012905\n",
      "40\n",
      "{'colsample_bytree': 0.75, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.000926597538401 0.0125464898243\n",
      "41\n",
      "{'colsample_bytree': 0.75, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 2, 'subsample': 0.7}\n",
      "0.00111100869943 0.0180487036761\n",
      "42\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 2, 'subsample': 0.85}\n",
      "0.00149317854911 0.015402549055\n",
      "43\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00108361016212 0.0153065826862\n",
      "44\n",
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00114170785624 0.0128564557912\n",
      "45\n",
      "{'colsample_bytree': 1, 'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 2, 'subsample': 0.7}\n",
      "0.00101802039479 0.0149934371058\n",
      "46\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00148772878711 0.0179133632598\n",
      "47\n",
      "{'colsample_bytree': 1, 'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.00230313405145 0.0153895594591\n",
      "48\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.000847562967286 0.0160441267943\n",
      "49\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'reg_lambda': 1, 'subsample': 0.85}\n",
      "0.00097011396042 0.015561638229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-44d7e825c637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    249\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/magnusterra/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'objective':['reg:linear', 'reg:gamma'], 'max_depth':[1,2,3,4],\n",
    "                    'gamma':[0, 1e-3, 1e-2,  1e-4], 'subsample':[0.85, 0.7],\n",
    "                   'colsample_bytree':[0.5, 0.75, 1], 'reg_lambda':[1,2]}\n",
    "scores = ['MSE']\n",
    "for i in range(100):\n",
    "    subxtrain, subxval, subytrain, subyval = train_test_split(trndfx.values, trny.values, test_size=0.2, random_state=i)\n",
    "    \n",
    "    clf = GridSearchCV(estimator =XGBRegressor(), param_grid =tuned_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "    clf.fit(subxtrain, subytrain)\n",
    "    print(i)\n",
    "    print(clf.best_params_)  \n",
    "    y_pred1 = clf.predict(subxtrain)\n",
    "    mse1 = MSE(y_pred1, subytrain)\n",
    "    y_pred2 = clf.predict(subxval)\n",
    "    mse2 = MSE(subyval, y_pred2)\n",
    "    print(mse1, mse2)\n",
    "print(\"----------------------------------\")\n",
    "clf = GridSearchCV(estimator =XGBRegressor(), param_grid =tuned_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "clf.fit(trndfx.value, trny.values)\n",
    "print(clf.best_params_)  \n",
    "y_pred1 = clf.predict(trndfx.value)\n",
    "print(MSE(y_pred1, trny.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0143759856513 0.00165673281146 0.0193661159421 0.0104029329989\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(100):\n",
    "    subxtrain, subxval, subytrain, subyval = train_test_split(trndfx.values, trny.values, test_size=0.2, random_state=i)\n",
    "    \n",
    "    xgb = XGBRegressor(gamma=0.0001, max_depth=4, objective='reg:linear')\n",
    "    xgb.fit(subxtrain, subytrain)\n",
    "    test1_pred = xgb.predict(subxval)\n",
    "    t = MSE(test1_pred, subyval)\n",
    "    results.append(t)\n",
    "print(np.mean(results), np.std(results), np.max(results), np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop one low point and first time 0.014741465827 0.00162512429795 0.0189895926045 0.0105734644657\n",
    "# gamma 0.001 maxdepth 4  reglinear 0.0144610802404 0.00175733689859 0.0196985530573 0.0100834249352\n",
    "# gamma 0.0001 maxdepth 4 reglinear 0.0143856951298 0.00170540998626 0.0191399670418 0.00971191056159\n",
    "# colsample_bytree 0.75 subsample 0.85 0.0142421094143 0.00181883817878 0.0197610426883 0.010295341613\n",
    "# gamma 0.0001 maxdepth 4 reggamma  0.0149096180762 0.00172825596149 0.0199681654468 0.010476040449\n",
    "# gamma 0.0001 maxdepth 3 reglinear 0.0147272494118 0.00162162861641 0.0189899116751 0.0105731757251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0667875043903\n",
      "0.0639566714423\n",
      "0.0662796512958\n",
      "0.0655412960678\n",
      "0.0662920383448\n",
      "0.0655230259902\n",
      "0.0607955913241\n",
      "0.0631220491814\n",
      "0.0637432964298\n",
      "0.0632103322711\n",
      "0.0606378348564\n",
      "0.0610464684039\n",
      "0.0666560580885\n",
      "0.0664667043301\n",
      "0.0642778931019\n",
      "0.0648257475045\n",
      "0.061317761155\n",
      "0.0639878491319\n",
      "0.0617881318216\n",
      "0.065396844497\n",
      "0.0632319641659\n",
      "0.0658815384733\n",
      "0.0654728547835\n",
      "0.0650374444198\n",
      "0.0638208359601\n",
      "0.0603828982556\n",
      "0.0635416629148\n",
      "0.062053435724\n",
      "0.0634516671694\n",
      "0.0646066783626\n",
      "0.0651099018204\n",
      "0.0631536667199\n",
      "0.06539549973\n",
      "0.0628728664347\n",
      "0.0648070352683\n",
      "0.0649789869466\n",
      "0.0638124927033\n",
      "0.0684285401821\n",
      "0.0600031681137\n",
      "0.063076508852\n",
      "0.0667324006048\n",
      "0.0619947071055\n",
      "0.0647441842258\n",
      "0.0637976361614\n",
      "0.0632864589939\n",
      "0.0638321666021\n",
      "0.0632500693105\n",
      "0.0631557793934\n",
      "0.0620323755622\n",
      "0.0653453908303\n",
      "0.0654716446384\n",
      "0.0653208844355\n",
      "0.0653168611421\n",
      "0.0625671968117\n",
      "0.0656561167129\n",
      "0.0654098099998\n",
      "0.0662353952486\n",
      "0.0620449108842\n",
      "0.0635409773378\n",
      "0.0643381742026\n",
      "0.0615903307172\n",
      "0.0639980558596\n",
      "0.0623506889741\n",
      "0.0652967963899\n",
      "0.0622766810812\n",
      "0.0630808580423\n",
      "0.0639764863887\n",
      "0.0667692240975\n",
      "0.06566706526\n",
      "0.0631182799443\n",
      "0.0657274256766\n",
      "0.062408470223\n",
      "0.0625219648894\n",
      "0.063388030249\n",
      "0.0635028249453\n",
      "0.0644306299669\n",
      "0.0641869281393\n",
      "0.063329827552\n",
      "0.0633613640384\n",
      "0.0628744738189\n",
      "0.0627510572731\n",
      "0.0643047538037\n",
      "0.0673294675979\n",
      "0.0636922012508\n",
      "0.0614240412423\n",
      "0.0628410228472\n",
      "0.0629248589245\n",
      "0.0614919474837\n",
      "0.0628972326415\n",
      "0.0643638264369\n",
      "0.0645970081742\n",
      "0.0646766467521\n",
      "0.0660420553905\n",
      "0.063466157456\n",
      "0.064664695166\n",
      "0.0655930459986\n",
      "0.0636715313354\n",
      "0.065289524446\n",
      "0.0625240601654\n",
      "0.0651220607937\n",
      "0.0633196474046 0.00439787343863 0.0751380365115 0.053865747991\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(100):\n",
    "    subxtrain, subxval, subytrain, subyval = train_test_split(trndfx.values, trny.values, test_size=0.2, random_state=i)\n",
    "    xgb = XGBRegressor()\n",
    "    tr_pred, tepred = get_oof(xgb, subxtrain, subytrain, subxval, len(subytrain), len(subyval))\n",
    "    print(MSE(tr_pred, subytrain))\n",
    "    t = MSE(tepred, subyval)\n",
    "    results.append(t)\n",
    "print(np.mean(results), np.std(results), np.max(results), np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00135708685441\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(gamma=0.0001, max_depth=4, objective='reg:linear')\n",
    "xgb.fit(trndfx.values, trny.values)\n",
    "test1_pred = xgb.predict(trndfx.values)\n",
    "print(MSE(test1_pred, trny.values))\n",
    "test1_pred = xgb.predict(ndfx[800:1100].values)\n",
    "test1_pred = test1_pred.reshape(300)\n",
    "save = pd.DataFrame({'ID':test1_id, 'value':test1_pred})\n",
    "save.to_csv('answer/Synchronous_logohtime_xgb_20180119.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 1533)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 : GradientBoostingRegressor\n",
    "# 1 : ExtraTreesRegressor\n",
    "# 2 : RandomForestRegressor\n",
    "# 3 : SVM Regressor(RBF Kernel)\n",
    "# 4 : KNN Regressor(Distance-weighted)\n",
    "# 5 : Decision TreeRegressor\n",
    "# 6 : KNN Regressor (Uniform-weighted)\n",
    "# 7 : LinearRegression\n",
    "# 8 : SGDRegressor\n",
    "# 9 : SVM Regressor(Linear Kernel)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "def Regressor(number):\n",
    "    if number == 0:\n",
    "        return GradientBoostingRegressor()\n",
    "    elif number == 1:\n",
    "        return ExtraTreesRegressor()\n",
    "    elif number == 2:\n",
    "        return RandomForestRegressor()\n",
    "    elif number == 3:\n",
    "        return SVR(kernel='rbf')\n",
    "    elif number == 4:\n",
    "        return KNeighborsRegressor(weights='distance')\n",
    "    elif number == 5:\n",
    "        return DecisionTreeRegressor()\n",
    "    elif number == 6:\n",
    "        return KNeighborsRegressor(weights='uniform')\n",
    "    elif number == 7:\n",
    "        return LinearRegression()\n",
    "    elif number == 8:\n",
    "        return SGDRegressor()\n",
    "    elif number == 9:\n",
    "        return SVR(kernel='linear')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    results = []\n",
    "    for i in range(100):\n",
    "        subxtrain, subxval, subytrain, subyval = train_test_split(trndfx.values, trny.values, test_size=0.2, random_state=i)\n",
    "        xgb = Regressor()\n",
    "        tr_pred, tepred = get_oof(xgb, subxtrain, subytrain, subxval, len(subytrain), len(subyval))\n",
    "        t = MSE(tepred, subyval)\n",
    "        results.append(t)\n",
    "    print(np.mean(results), np.std(results), np.max(results), np.min(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
