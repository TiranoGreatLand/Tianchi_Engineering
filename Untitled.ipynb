{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read train and test data\n",
    "train_data = pd.read_excel('训练.xlsx')\n",
    "test_data_1 = pd.read_excel('测试A.xlsx')\n",
    "test_data_2 = pd.read_excel('测试B.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nonnull = train_data.isnull().values\n",
    "test_nonnull_1 = test_data_1.isnull().values\n",
    "test_nonnull_2 = test_data_2.isnull().values\n",
    "train_X = train_data.values\n",
    "test_X_1 = test_data_1.values\n",
    "test_X_2 = test_data_2.values\n",
    "test_id_1 = test_X_1[:, 0]\n",
    "test_id_2 = test_X_2[:, 0]\n",
    "train_y = train_X[:, -1]\n",
    "train_X = train_X[:, 1:-1]\n",
    "test_X_1 = test_X_1[:, 1:]\n",
    "test_X_2 = test_X_2[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027) (721, 8027)\n"
     ]
    }
   ],
   "source": [
    "#Merge two data\n",
    "merged_X = np.concatenate((train_X, test_X_1, test_X_2), axis=0)\n",
    "merged_nn = np.concatenate((train_nonnull[:, 1:-1], test_nonnull_1[:, 1:], test_nonnull_2[:, 1:]), axis=0)\n",
    "print(merged_X.shape, merged_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reverse nn\n",
    "def BoolReverse(columns):\n",
    "    tmpm = np.zeros(columns.shape)\n",
    "    tmpm[columns] = 1\n",
    "    return tmpm == 0\n",
    "\n",
    "merged_nn = BoolReverse(merged_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# now find the values that has 0 value and delete such column\n",
    "first_delete_idxs = []\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    if len(rd) == 0:\n",
    "        first_delete_idxs.append(i)\n",
    "    elif len(set(rd)) == 0:\n",
    "        first_delete_idxs.append(i)\n",
    "print(len(first_delete_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027)\n",
      "(721, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(merged_X.shape)\n",
    "merged_X = np.delete(merged_X, first_delete_idxs, axis=1)\n",
    "print(merged_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8027)\n",
      "(721, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(merged_nn.shape)\n",
    "merged_nn = np.delete(merged_nn, first_delete_idxs, axis=1)\n",
    "print(merged_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n"
     ]
    }
   ],
   "source": [
    "#now find the columns that has only one value\n",
    "only_one_values = 0\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    if len(set(rd)) == 1:\n",
    "        merged_X[:, i] = 1.0\n",
    "        merged_nn[:, i] = True\n",
    "        only_one_values += 1\n",
    "print(only_one_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic):\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "# input one array and return the most frequent one\n",
    "def MostFrequentOne(column):\n",
    "    itemfreq = {}\n",
    "    for i in column:\n",
    "        if i not in itemfreq:\n",
    "            itemfreq[i] = 1\n",
    "        else:\n",
    "            itemfreq[i] += 1\n",
    "    tmp_dict = sorted(dict2list(itemfreq), key=lambda d:d[1], reverse=True)\n",
    "    return tmp_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one_hot to map str to int\n",
    "def OneHot_Str(column, retdict = 0):\n",
    "    syms = set(column)\n",
    "    sim = {}\n",
    "    count = 0\n",
    "    for s in syms:\n",
    "        sim[s] = count\n",
    "        count += 1\n",
    "    cl = len(column)\n",
    "    retoh = np.zeros((cl, count))\n",
    "    for i in range(cl):\n",
    "        s = column[i]\n",
    "        mi = sim[s]\n",
    "        retoh[i, mi] = 1.0\n",
    "    if retdict == 0:\n",
    "        return retoh\n",
    "    else:\n",
    "        return retoh, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(721, 7999)\n",
      "(721, 7989)\n"
     ]
    }
   ],
   "source": [
    "#now fix the remain data\n",
    "#if the values in data has one value that is string, then one_hot it, else normalize it\n",
    "stridxs = []\n",
    "for i in range(merged_X.shape[1]):\n",
    "    data = merged_X[:, i]\n",
    "    real = merged_nn[:, i]\n",
    "    rd = data[real]\n",
    "    #if len(data) == len(rd) and np.mean(data) == 1.0:\n",
    "    #    continue\n",
    "    isstr = False\n",
    "    for j in range(len(rd)):\n",
    "        x = rd[j]\n",
    "        sx = str(type(x))\n",
    "        if 'str' in sx:\n",
    "            isstr = True\n",
    "            break\n",
    "    if isstr:\n",
    "        stridxs.append(i)\n",
    "        # fix null and one_hot it\n",
    "        if len(rd) < len(data):\n",
    "            mfc = MostFrequentOne(rd)\n",
    "            rn = BoolReverse(real)\n",
    "            data[rn] = mfc\n",
    "        onehots = OneHot_Str(data)\n",
    "        merged_X = np.concatenate((merged_X, onehots), axis=1)\n",
    "    else:\n",
    "        if len(rd) < len(data):\n",
    "            if len(set(data)) == 1:\n",
    "                continue\n",
    "            rn = BoolReverse(real)\n",
    "            data[rn] = np.mean(rd)\n",
    "            maxv = np.max(data)\n",
    "            minv = np.min(data)\n",
    "            data = (data-minv)/(maxv-minv)\n",
    "            merged_X[:, i] = data\n",
    "#delete the string columns\n",
    "print(len(stridxs))\n",
    "print(merged_X.shape)\n",
    "merged_X = np.delete(merged_X, stridxs, axis=1)\n",
    "print(merged_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#now use pca to reduce its demension\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regression by machinr learn\n",
    "def MSE_np(y, y_pred):\n",
    "    return np.mean(np.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 : GradientBoostingRegressor\n",
    "# 1 : ExtraTreesRegressor\n",
    "# 2 : RandomForestRegressor\n",
    "# 3 : SVM Regressor(RBF Kernel)\n",
    "# 4 : KNN Regressor(Distance-weighted)\n",
    "# 5 : Decision TreeRegressor\n",
    "# 6 : KNN Regressor (Uniform-weighted)\n",
    "# 7 : LinearRegression\n",
    "# 8 : SGDRegressor\n",
    "# 9 : SVM Regressor(Linear Kernel)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "def Regressor(number):\n",
    "    if number == 0:\n",
    "        return GradientBoostingRegressor()\n",
    "    elif number == 1:\n",
    "        return ExtraTreesRegressor()\n",
    "    elif number == 2:\n",
    "        return RandomForestRegressor()\n",
    "    elif number == 3:\n",
    "        return SVR(kernel='rbf')\n",
    "    elif number == 4:\n",
    "        return KNeighborsRegressor(weights='distance')\n",
    "    elif number == 5:\n",
    "        return DecisionTreeRegressor()\n",
    "    elif number == 6:\n",
    "        return KNeighborsRegressor(weights='uniform')\n",
    "    elif number == 7:\n",
    "        return LinearRegression()\n",
    "    elif number == 8:\n",
    "        return SGDRegressor()\n",
    "    elif number == 9:\n",
    "        return SVR(kernel='linear')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_time = time.time()\n",
    "best_cn = 0\n",
    "best_val_mse = 1\n",
    "best_regressor = None\n",
    "#regressor\n",
    "for i in range(10):\n",
    "    #cn\n",
    "    for j in range(10, 50):\n",
    "        mses = []\n",
    "        cn = j \n",
    "        pca = PCA(n_components=cn) \n",
    "        pca.fit(merged_X) \n",
    "        X_new = pca.transform(merged_X)\n",
    "        for k in range(cn):\n",
    "            col = X_new[:, k]\n",
    "            m = np.mean(col)\n",
    "            s = np.std(col)\n",
    "            col = (col-m)/s\n",
    "            maxv = np.max(col)\n",
    "            minv = np.min(col)\n",
    "            col = (col-minv)/(maxv-minv)\n",
    "            X_new[:, k] = col\n",
    "        trainX = X_new[:500]\n",
    "        test1X = X_new[500:600]\n",
    "        test2X = X_new[600:]\n",
    "        mses = []\n",
    "        #random state\n",
    "        for k in range(0, 100):\n",
    "            trX, vaX, tr_y, va_y = train_test_split(trainX, train_y, test_size=0.2, random_state=k)\n",
    "            regressor = Regressor(i)\n",
    "            regressor.fit(trX, tr_y)\n",
    "            va_p = regressor.predict(vaX)\n",
    "            mse = MSE_np(va_y, va_p)\n",
    "            mses.append(mses)\n",
    "        mse = np.mean(mses)\n",
    "        if mse < best_val_mse:\n",
    "            best_cn = j\n",
    "            best_regressor = i\n",
    "            best_val_mse = mse\n",
    "        print(i, j, time.time()-cur_time, mse)\n",
    "        cur_time = time.time()\n",
    "print(\"best regressor\", best_regressor, \"best cn\", best_cn, best_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
