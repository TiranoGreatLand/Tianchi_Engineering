{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"训练.xlsx\")\n",
    "test1_df = pd.read_excel(\"测试A.xlsx\")\n",
    "test2_df = pd.read_excel(\"测试B.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_column = test1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_df[train_df.columns[-1]]\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[new_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id = train_df['ID']\n",
    "test1_id = test1_df['ID']\n",
    "test2_id = test2_df['ID']\n",
    "train_df.drop(['ID'], axis=1, inplace=True)\n",
    "test1_df.drop(['ID'], axis=1, inplace=True)\n",
    "test2_df.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = train_df.columns\n",
    "dts = train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815\n"
     ]
    }
   ],
   "source": [
    "drop_names = []\n",
    "ratio = 0.125\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    tp = dts[i]\n",
    "    trd = train_df[n]\n",
    "    ted = test1_df[n]\n",
    "    if 'object' == str(tp):\n",
    "        continue\n",
    "    else:\n",
    "        misstr = np.sum(trd.isnull())/500\n",
    "        misste = np.sum(ted.isnull())/100\n",
    "        if np.abs(misstr-misste) > ratio:\n",
    "            drop_names.append(n)\n",
    "        else:\n",
    "            if 'int' in str(tp):\n",
    "                continue\n",
    "            trrd = trd[trd.notnull()]\n",
    "            terd = ted[ted.notnull()]\n",
    "            m1 = np.mean(trrd)\n",
    "            s1 = np.std(trrd)\n",
    "            m2 = np.mean(terd)\n",
    "            s2 = np.std(terd)\n",
    "            if np.abs(m1-m2)>ratio*np.abs(m1) and np.abs(s1-s2)>ratio*np.abs(s1):\n",
    "                drop_names.append(n)\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(drop_names, axis=1, inplace=True)\n",
    "test1_df.drop(drop_names, axis=1, inplace=True)\n",
    "test2_df.drop(drop_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = train_df.columns\n",
    "dfs = train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n"
     ]
    }
   ],
   "source": [
    "# ints or strings\n",
    "ints = []\n",
    "for i in range(len(names)):\n",
    "    if 'int' in str(dfs[i]) or 'object' in str(dfs[i]):\n",
    "        ints.append(names[i])\n",
    "print(len(ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = pd.concat([train_df, test1_df, test2_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 473 766\n"
     ]
    }
   ],
   "source": [
    "remains1 = []\n",
    "remains2 = []\n",
    "tobedrop = []\n",
    "for n in ints:\n",
    "    lu1 = len(train_df[n].unique())\n",
    "    lu2 = len(df_X[n].unique())\n",
    "    if lu1 < 10 and lu1 > 1:\n",
    "        remains1.append(n)\n",
    "    if lu2 < 10 and lu2 > 1:\n",
    "        remains2.append(n)\n",
    "    if lu1 != lu2:\n",
    "        tobedrop.append(n)\n",
    "print(len(remains1), len(remains2), len(tobedrop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 179 97\n"
     ]
    }
   ],
   "source": [
    "print(len(set(tobedrop) & set(remains1)), len(set(tobedrop) & set(remains2)), len(set(tobedrop) & set(remains2) & set(remains1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "toberemain = list(set(remains1) & set(remains2) - set(tobedrop))\n",
    "print(len(toberemain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict2list(dic:dict):\n",
    "    ''' 将字典转化为列表 '''\n",
    "    keys = dic.keys()\n",
    "    vals = dic.values()\n",
    "    lst = [(key, val) for key, val in zip(keys, vals)]\n",
    "    return lst\n",
    "\n",
    "def LastRemainJudge(column):\n",
    "    unique = set(column)\n",
    "    uf = {}\n",
    "    for u in unique:\n",
    "        uf[u] = 0\n",
    "    for c in column:\n",
    "        uf[c] += 1\n",
    "    sl = sorted(dict2list(uf), key = lambda x:x[1], reverse=True)\n",
    "    x = sl[0][1]/len(column)\n",
    "    sl = np.array(sl)\n",
    "    if x < 0.8:\n",
    "        #print(sl[:, 1]/len(column))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 189 183\n"
     ]
    }
   ],
   "source": [
    "lm1 = []\n",
    "lm2 = []\n",
    "for n in toberemain:\n",
    "    if LastRemainJudge(train_df[n]):\n",
    "        lm1.append(n)\n",
    "    if LastRemainJudge(df_X[n]):\n",
    "        lm2.append(n)\n",
    "print(len(lm1), len(lm2), len(set(lm1)&set(lm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = df_X.columns\n",
    "dts = df_X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "5668\n",
      "(721, 5668) (721, 183)\n"
     ]
    }
   ],
   "source": [
    "dfx_float_n = []\n",
    "dfx_onehot_n = list(set(lm1) & set(lm2))\n",
    "print(len(dfx_onehot_n))\n",
    "for i in range(len(names)):\n",
    "    n = names[i]\n",
    "    d = dts[i]\n",
    "    if 'float' in str(d):\n",
    "        dfx_float_n.append(n)\n",
    "print(len(dfx_float_n))\n",
    "dfx_float = df_X[dfx_float_n]\n",
    "dfx_onehot = df_X[dfx_onehot_n]\n",
    "print(dfx_float.shape, dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "drop_names = []\n",
    "for n in dfx_float_n:\n",
    "    x = np.sum(dfx_float[n].isnull())\n",
    "    if x > 300:\n",
    "        drop_names.append(n)\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfx_float.drop(drop_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180 2180\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "stds = []\n",
    "drop_names = []\n",
    "names = dfx_float.columns\n",
    "for n in names:\n",
    "    c = dfx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    means.append(tmpm)\n",
    "    stds.append(tmps)\n",
    "    if tmps == 0:\n",
    "        drop_names.append(n)\n",
    "print(len(set(means)), len(set(stds)))\n",
    "print(len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n"
     ]
    }
   ],
   "source": [
    "# not move sames first, fill nan\n",
    "added = set()\n",
    "sames = []\n",
    "for i in range(len(names)):\n",
    "    tmpsl = []\n",
    "    tmpsl.append(i)\n",
    "    for j in range(i+1, len(names)):\n",
    "        if means[i] == means[j] and stds[i] == stds[j]:\n",
    "            if i not in added:\n",
    "                added.add(i)\n",
    "            if j not in added:\n",
    "                added.add(j)\n",
    "                tmpsl.append(j)\n",
    "    if len(tmpsl) > 1:\n",
    "        sames.append(tmpsl)\n",
    "print(len(sames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3157\n",
      "(721, 5338)\n"
     ]
    }
   ],
   "source": [
    "names = dfx_float.columns\n",
    "drop_names = []\n",
    "for i in sames:\n",
    "    for j in i[1:]:\n",
    "        drop_names.append(names[j])\n",
    "print(len(drop_names))\n",
    "print(dfx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 2181)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "trainx_float = copy.copy(dfx_float)\n",
    "trainx_float.drop(drop_names, axis=1, inplace=True)\n",
    "print(trainx_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 2181)\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "names = trainx_float.columns\n",
    "print(trainx_float.shape)\n",
    "drop_names = []\n",
    "for n in names:\n",
    "    c = trainx_float[n]\n",
    "    r = c[c.notnull()]\n",
    "    tmpm = np.mean(r)\n",
    "    tmps = np.std(r)\n",
    "    if tmps>0:\n",
    "        trainx_float[n][c.isnull()] = tmpm\n",
    "    else:\n",
    "        drop_names.append(n)\n",
    "print(np.sum(trainx_float.isnull().values), len(drop_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "trainx_float.drop(drop_names, axis=1, inplace=True)\n",
    "print(np.sum(trainx_float.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 2181)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# it shall be that there is only thre lines with nan in log1p\n",
    "mid = trainx_float-np.min(trainx_float)+1\n",
    "trainx_log1p = np.log1p(mid)\n",
    "del mid\n",
    "print(np.sum(trainx_log1p.isnull().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = trainx_float.columns\n",
    "for n in names:\n",
    "    m1 = np.mean(trainx_float[n])\n",
    "    s1 = np.std(trainx_float[n])\n",
    "    assert s1 > 0\n",
    "    trainx_float[n] = (trainx_float[n]-m1)/s1\n",
    "    m2 = np.mean(trainx_log1p[n])\n",
    "    s2 = np.std(trainx_log1p[n])\n",
    "    assert s2 > 0\n",
    "    trainx_log1p[n] = (trainx_log1p[n]-m2)/s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 192)\n",
      "(721, 200)\n",
      "(721, 204)\n",
      "(721, 208)\n",
      "(721, 215)\n",
      "(721, 218)\n",
      "(721, 223)\n",
      "(721, 225)\n",
      "(721, 231)\n",
      "(721, 233)\n",
      "(721, 235)\n",
      "(721, 238)\n",
      "(721, 242)\n",
      "(721, 245)\n",
      "(721, 247)\n",
      "(721, 253)\n",
      "(721, 256)\n",
      "(721, 263)\n",
      "(721, 268)\n",
      "(721, 273)\n",
      "(721, 279)\n",
      "(721, 281)\n",
      "(721, 283)\n",
      "(721, 287)\n",
      "(721, 291)\n",
      "(721, 300)\n",
      "(721, 304)\n",
      "(721, 306)\n",
      "(721, 309)\n",
      "(721, 311)\n",
      "(721, 314)\n",
      "(721, 323)\n",
      "(721, 326)\n",
      "(721, 328)\n",
      "(721, 331)\n",
      "(721, 335)\n",
      "(721, 337)\n",
      "(721, 340)\n",
      "(721, 349)\n",
      "(721, 354)\n",
      "(721, 358)\n",
      "(721, 362)\n",
      "(721, 370)\n",
      "(721, 373)\n",
      "(721, 376)\n",
      "(721, 385)\n",
      "(721, 387)\n",
      "(721, 389)\n",
      "(721, 392)\n",
      "(721, 396)\n",
      "(721, 399)\n",
      "(721, 406)\n",
      "(721, 408)\n",
      "(721, 417)\n",
      "(721, 419)\n",
      "(721, 425)\n",
      "(721, 431)\n",
      "(721, 433)\n",
      "(721, 439)\n",
      "(721, 446)\n",
      "(721, 450)\n",
      "(721, 452)\n",
      "(721, 457)\n",
      "(721, 464)\n",
      "(721, 469)\n",
      "(721, 475)\n",
      "(721, 478)\n",
      "(721, 484)\n",
      "(721, 487)\n",
      "(721, 493)\n",
      "(721, 497)\n",
      "(721, 506)\n",
      "(721, 513)\n",
      "(721, 518)\n",
      "(721, 523)\n",
      "(721, 525)\n",
      "(721, 529)\n",
      "(721, 534)\n",
      "(721, 536)\n",
      "(721, 545)\n",
      "(721, 548)\n",
      "(721, 552)\n",
      "(721, 554)\n",
      "(721, 557)\n",
      "(721, 559)\n",
      "(721, 561)\n",
      "(721, 564)\n",
      "(721, 566)\n",
      "(721, 571)\n",
      "(721, 577)\n",
      "(721, 584)\n",
      "(721, 590)\n",
      "(721, 592)\n",
      "(721, 596)\n",
      "(721, 603)\n",
      "(721, 612)\n",
      "(721, 618)\n",
      "(721, 620)\n",
      "(721, 625)\n",
      "(721, 628)\n",
      "(721, 637)\n",
      "(721, 642)\n",
      "(721, 647)\n",
      "(721, 650)\n",
      "(721, 657)\n",
      "(721, 661)\n",
      "(721, 664)\n",
      "(721, 667)\n",
      "(721, 674)\n",
      "(721, 676)\n",
      "(721, 683)\n",
      "(721, 692)\n",
      "(721, 699)\n",
      "(721, 708)\n",
      "(721, 713)\n",
      "(721, 717)\n",
      "(721, 725)\n",
      "(721, 728)\n",
      "(721, 730)\n",
      "(721, 735)\n",
      "(721, 737)\n",
      "(721, 741)\n",
      "(721, 743)\n",
      "(721, 748)\n",
      "(721, 751)\n",
      "(721, 753)\n",
      "(721, 756)\n",
      "(721, 758)\n",
      "(721, 767)\n",
      "(721, 769)\n",
      "(721, 775)\n",
      "(721, 779)\n",
      "(721, 782)\n",
      "(721, 788)\n",
      "(721, 791)\n",
      "(721, 797)\n",
      "(721, 799)\n",
      "(721, 803)\n",
      "(721, 805)\n",
      "(721, 807)\n",
      "(721, 809)\n",
      "(721, 812)\n",
      "(721, 816)\n",
      "(721, 820)\n",
      "(721, 823)\n",
      "(721, 831)\n",
      "(721, 836)\n",
      "(721, 839)\n",
      "(721, 842)\n",
      "(721, 844)\n",
      "(721, 850)\n",
      "(721, 852)\n",
      "(721, 854)\n",
      "(721, 856)\n",
      "(721, 859)\n",
      "(721, 861)\n",
      "(721, 863)\n",
      "(721, 865)\n",
      "(721, 867)\n",
      "(721, 869)\n",
      "(721, 871)\n",
      "(721, 873)\n",
      "(721, 881)\n",
      "(721, 889)\n",
      "(721, 891)\n",
      "(721, 900)\n",
      "(721, 909)\n",
      "(721, 912)\n",
      "(721, 914)\n",
      "(721, 917)\n",
      "(721, 920)\n",
      "(721, 922)\n",
      "(721, 929)\n",
      "(721, 931)\n",
      "(721, 935)\n",
      "(721, 938)\n",
      "(721, 947)\n",
      "(721, 953)\n",
      "(721, 955)\n",
      "(721, 959)\n",
      "(721, 962)\n",
      "(721, 970)\n",
      "(721, 974)\n"
     ]
    }
   ],
   "source": [
    "# make onehots onehot\n",
    "ohnames = dfx_onehot.columns\n",
    "for i in range(len(ohnames)):\n",
    "    n = ohnames[i]\n",
    "    tmp = pd.get_dummies(dfx_onehot[n], prefix='onehot_'+str(i))\n",
    "    dfx_onehot = pd.concat([dfx_onehot, tmp], axis=1)\n",
    "    print(dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 791)\n"
     ]
    }
   ],
   "source": [
    "dfx_onehot.drop(ohnames, axis=1, inplace=True)\n",
    "print(dfx_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx_float = trainx_float\n",
    "dfx_log1p = trainx_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = dfx_float.columns\n",
    "lr = LinearRegression()\n",
    "lr.fit(dfx_float[:500], train_y)\n",
    "fn = names[lr.coef_>0]\n",
    "lr = LinearRegression()\n",
    "lr.fit(dfx_log1p[:500], train_y)\n",
    "ln = names[lr.coef_>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfloatlr = dfx_float[fn]\n",
    "xlog1plr = dfx_log1p[ln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n",
      "(721, 338)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(dfx_onehot[:500], train_y)\n",
    "print(np.sum(lr.coef_>0))\n",
    "names = dfx_onehot.columns\n",
    "xonehot = dfx_onehot[names[lr.coef_>0]]\n",
    "print(xonehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_raw, y_pred):\n",
    "    print(np.mean(np.square(y_raw-y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magnusterra/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subxtrain, subxval, subytrain, subyval = train_test_split(dfx_log1p[:500].values, train_y.values, test_size=0.2, random_state=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.01, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.039 (+/-0.005) for {'gamma': 0, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.008) for {'gamma': 0, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.007) for {'gamma': 0, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.009) for {'gamma': 0, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.036 (+/-0.007) for {'gamma': 0, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.007) for {'gamma': 0, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.004) for {'gamma': 0, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.006) for {'gamma': 0, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.009) for {'gamma': 0, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.008) for {'gamma': 0, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.039 (+/-0.003) for {'gamma': 0, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.039 (+/-0.005) for {'gamma': 0.001, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.001, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.001, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.008) for {'gamma': 0.001, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.001, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.001, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.001, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.001, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.036 (+/-0.007) for {'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.007) for {'gamma': 0.001, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.005) for {'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.008) for {'gamma': 0.001, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.039 (+/-0.006) for {'gamma': 0.001, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.003) for {'gamma': 0.001, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.008) for {'gamma': 0.001, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.001, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.001, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.039 (+/-0.004) for {'gamma': 0.001, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0.001, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.001, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.039 (+/-0.005) for {'gamma': 0.01, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.01, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.01, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.01, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.01, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.01, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.01, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.01, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.003) for {'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.004) for {'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.006) for {'gamma': 0.01, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.004) for {'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.005) for {'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.003) for {'gamma': 0.01, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.008) for {'gamma': 0.01, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.007) for {'gamma': 0.01, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.005) for {'gamma': 0.01, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.006) for {'gamma': 0.01, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.007) for {'gamma': 0.01, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.003) for {'gamma': 0.01, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.035 (+/-0.005) for {'gamma': 0.01, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.01, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.039 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.007) for {'gamma': 0.0001, 'max_depth': 1, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.008) for {'gamma': 0.0001, 'max_depth': 1, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 2, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.006) for {'gamma': 0.0001, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 2, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.007) for {'gamma': 0.0001, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 3, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.007) for {'gamma': 0.0001, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.036 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 3, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.004) for {'gamma': 0.0001, 'max_depth': 4, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.038 (+/-0.006) for {'gamma': 0.0001, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.037 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 5, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.036 (+/-0.006) for {'gamma': 0.0001, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.008) for {'gamma': 0.0001, 'max_depth': 5, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "-0.037 (+/-0.008) for {'gamma': 0.0001, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.85}\n",
      "-0.039 (+/-0.003) for {'gamma': 0.0001, 'max_depth': 6, 'objective': 'reg:linear', 'subsample': 0.7}\n",
      "-0.037 (+/-0.008) for {'gamma': 0.0001, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.85}\n",
      "-0.038 (+/-0.005) for {'gamma': 0.0001, 'max_depth': 6, 'objective': 'reg:gamma', 'subsample': 0.7}\n",
      "\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "0.0231871927737\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'objective':['reg:linear', 'reg:gamma'], 'max_depth':[1,2,3,4,5,6],\n",
    "                    'gamma':[0, 1e-3, 1e-2,  1e-4], 'subsample':[0.85, 0.7]}\n",
    "scores = ['MSE']\n",
    "clf = GridSearchCV(estimator =XGBRegressor(), param_grid =tuned_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "clf.fit(subxtrain, subytrain)\n",
    "print(\"Best parameters set found on development set:\")  \n",
    "print()  \n",
    "print(clf.best_params_)  \n",
    "print()  \n",
    "print(\"Grid scores on development set:\")  \n",
    "print()  \n",
    "for params, mean_score, scores in clf.grid_scores_:  \n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"  \n",
    "              % (mean_score, scores.std() * 2, params))  \n",
    "print()\n",
    "print(\"The scores are computed on the full evaluation set.\")  \n",
    "print()  \n",
    "y_true, y_pred = subyval, clf.predict(subxval)\n",
    "print(MSE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_oof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-469b692b9ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#tr_pred, te_pred = get_oof(xgb, subxtrain, subytrain, subxval)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtr_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_oof' is not defined"
     ]
    }
   ],
   "source": [
    "#xgb = XGBRegressor(gamma=0.01, max_depth=6, objective='reg:gamma', subsample=0.85)\n",
    "nx = pd.concat([dfx_log1p, dfx_onehot], axis=1)\n",
    "subxtrain, subxval, subytrain, subyval = train_test_split(nx[:500].values, train_y.values, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.fit(dfx_log1p[:500], train_y)\n",
    "#test1_pred = Model_TripleTest(xfloatlr[:500], xlog1plr[:500], xexplr[:500], xonehot[:500], train_y, xfloatlr[500:600], xlog1plr[500:600], xexplr[500:600], xonehot[500:600])\n",
    "test1_pred = xgb.predict(dfx_log1p[500:600])\n",
    "save = pd.DataFrame({'ID':test1_id, 'value':test1_pred})\n",
    "save.to_csv('answer_Synchronous_param_log_ratio15_xgb_20180109.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=2018)\n",
    "def get_oof(rgr, xtrain, ytrain, xtest, lenot):\n",
    "    oof_train = np.zeros((lenot,))\n",
    "    oof_test = np.zeros((100,))\n",
    "    oof_test_skf = np.empty((5, 100))\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(xtrain)):\n",
    "        kf_xtrain = xtrain[train_index]\n",
    "        kf_ytrain = ytrain[train_index]\n",
    "        kf_xtest = xtrain[test_index]\n",
    "        rgr.fit(kf_xtrain, kf_ytrain)\n",
    "        oof_train[test_index] = rgr.predict(kf_xtest)\n",
    "        oof_test_skf[i, : ] = rgr.predict(xtest)\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0515541856481\n",
      "0.049627494265\n",
      "None None\n",
      "0.0505811417058\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#xgb = XGBRegressor(gamma=0.01, max_depth=6, objective='reg:gamma', subsample=0.85)\n",
    "xgb = XGBRegressor()\n",
    "tr_pred, te_pred = get_oof(xgb, subxtrain, subytrain, subxval, 400)\n",
    "print(MSE(tr_pred, subytrain), MSE(te_pred, subyval))\n",
    "xgb = XGBRegressor()\n",
    "#tr_pred, te_pred = get_oof(xgb, subxtrain, subytrain, subxval)\n",
    "tr_pred, te_pred = get_oof(xgb, nx[:500].values, train_y.values, nx[500:600].values, 500)\n",
    "print(MSE(tr_pred, subytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tr_pred, te_pred = get_oof(xgb, subxtrain, subytrain, dfx_log1p[500:600].values, 500)\n",
    "test1_pred = te_pred.reshape(100)\n",
    "save = pd.DataFrame({'ID':test1_id, 'value':test1_pred})\n",
    "save.to_csv('answer_Synchronous_paramstack_logratiooh125_xgb_20180109.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
